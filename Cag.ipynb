{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/automationcreators/flowchartmaker/blob/main/Cag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X__Kgw_wlQ8C"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = 'xxx'\n",
        "os.environ['FIRECRAWL_API_KEY'] = 'xxx'\n",
        "os.environ['HELICONE_API_KEY'] = 'xxx'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HfIQiMUlQ8C",
        "outputId": "43d2e1fe-73b0-487c-e8be-d51d7f29fa6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "121164"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "import pathlib\n",
        "import httpx\n",
        "import json\n",
        "\n",
        "client = genai.Client(\n",
        "    api_key=os.environ['GOOGLE_API_KEY'],\n",
        "    http_options={\n",
        "        \"base_url\": 'https://gateway.helicone.ai',\n",
        "        \"headers\": {\n",
        "            \"helicone-auth\": f'Bearer {os.environ.get(\"HELICONE_API_KEY\")}',\n",
        "            \"helicone-target-url\": 'https://generativelanguage.googleapis.com'\n",
        "        }\n",
        "    })\n",
        "\n",
        "doc_url = \"https://arxiv.org/pdf/2412.15605v1\"  # Replace with the actual URL of your PDF\n",
        "\n",
        "# Retrieve and encode the PDF byte\n",
        "filepath = pathlib.Path('file.pdf')\n",
        "filepath.write_bytes(httpx.get(doc_url).content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMlgw08hlQ8D"
      },
      "outputs": [],
      "source": [
        "prompt = \"Who are the authors\"\n",
        "response = client.models.generate_content(\n",
        "  model=\"gemini-2.0-flash\",\n",
        "  contents=[\n",
        "      types.Part.from_bytes(\n",
        "        data=filepath.read_bytes(),\n",
        "        mime_type='application/pdf',\n",
        "      ),\n",
        "      prompt])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeTg9Gd8lQ8D"
      },
      "source": [
        "## Example API assistant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rspr0kh3lQ8D"
      },
      "source": [
        "### Raw response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKLzzWwulQ8D",
        "outputId": "2d13e971-9b3c-4c29-fe7a-b59d1b274c9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```bash\n",
            "curl -X POST \\\n",
            "  'https://api.firecrawl.dev/crawler/crawl' \\\n",
            "  -H 'Content-Type: application/json' \\\n",
            "  -H 'X-Firecrawl-Api-Key: YOUR_FIRECRAWL_API_KEY' \\\n",
            "  -d '{\n",
            "  \"url\": \"https://ai-jason.com\",\n",
            "  \"options\": {\n",
            "    \"extract_rules\": {\n",
            "      \"page\": {\n",
            "        \"type\": \"json\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}'\n",
            "```\n",
            "\n",
            "**Important:**\n",
            "\n",
            "*   Replace `YOUR_FIRECRAWL_API_KEY` with your actual Firecrawl API key.\n",
            "*   This command uses the default `json` extractor on the whole page.  You'll likely want to define more specific extraction rules within the `extract_rules` section depending on what data you're trying to scrape from the site.  See Firecrawl documentation for details on defining extract rules.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def direct_llm_call(prompt):\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        contents=[prompt])\n",
        "    return(response.text)\n",
        "\n",
        "raw_response = direct_llm_call(\"Help me generate api request in curl for scrape'ai-jason.com' using firecrawl rest api, return only the curl command\")\n",
        "print(raw_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1XOaZm9lQ8E"
      },
      "source": [
        "### Actual implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyTrrTg9lQ8E"
      },
      "outputs": [],
      "source": [
        "from firecrawl import FirecrawlApp\n",
        "\n",
        "fire = FirecrawlApp(api_key=os.getenv(\"FIRECRAWL_API_KEY\"))\n",
        "\n",
        "url = \"https://docs.firecrawl.dev/\"\n",
        "\n",
        "# Get all links from the website\n",
        "all_links = fire.map_url(url).get('links')[1:]\n",
        "\n",
        "len(all_links)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ts3YbgyPlQ8E",
        "outputId": "5387404e-acfe-46ba-bfe0-cddcdf3e756a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def filter_api_doc_urls(doc_links):\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        contents=f\"{doc_links}, Above is list of urls, your goal is to extract all docs contain REST API reference, return only the urls\",\n",
        "        config={\n",
        "            \"response_mime_type\": \"application/json\",\n",
        "            \"response_schema\": list[str]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return json.loads(response.candidates[0].content.parts[0].text)\n",
        "\n",
        "api_doc_urls = filter_api_doc_urls(all_links)\n",
        "len(api_doc_urls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJN6Sd09lQ8E",
        "outputId": "bf1f6c6e-c44e-4820-dc68-cfe16948672b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'url': 'https://docs.firecrawl.dev/api-reference/endpoint/search',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nSearch Endpoints\\n\\nSearch\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nPOST\\n\\n/\\n\\nsearch\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/search \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"query\": \"<string>\",\\n  \"limit\": 5,\\n  \"tbs\": \"<string>\",\\n  \"lang\": \"en\",\\n  \"country\": \"us\",\\n  \"location\": \"<string>\",\\n  \"timeout\": 60000,\\n  \"scrapeOptions\": {}\\n}\\'\\n```\\n\\n200\\n\\n408\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"data\": [\\\\\\n    {\\\\\\n      \"title\": \"<string>\",\\\\\\n      \"description\": \"<string>\",\\\\\\n      \"url\": \"<string>\",\\\\\\n      \"markdown\": \"<string>\",\\\\\\n      \"html\": \"<string>\",\\\\\\n      \"rawHtml\": \"<string>\",\\\\\\n      \"links\": [\\\\\\n        \"<string>\"\\\\\\n      ],\\\\\\n      \"screenshot\": \"<string>\",\\\\\\n      \"metadata\": {\\\\\\n        \"title\": \"<string>\",\\\\\\n        \"description\": \"<string>\",\\\\\\n        \"sourceURL\": \"<string>\",\\\\\\n        \"statusCode\": 123,\\\\\\n        \"error\": \"<string>\"\\\\\\n      }\\\\\\n    }\\\\\\n  ],\\n  \"warning\": \"<string>\"\\n}\\n```\\n\\nThe search endpoint combines web search (SERP) with Firecrawlâ€™s scraping capabilities to return full page content for any query.\\n\\nInclude `scrapeOptions` with `formats: [\"markdown\"]` to get complete markdown content for each search result otherwise you will default to getting the SERP results (url, title, description).\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Body\\n\\napplication/json\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#body-query)\\n\\nquery\\n\\nstring\\n\\nrequired\\n\\nThe search query\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#body-limit)\\n\\nlimit\\n\\ninteger\\n\\ndefault:5\\n\\nMaximum number of results to return\\n\\nRequired range: `1 <= x <= 10`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#body-tbs)\\n\\ntbs\\n\\nstring\\n\\nTime-based search parameter\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#body-lang)\\n\\nlang\\n\\nstring\\n\\ndefault:en\\n\\nLanguage code for search results\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#body-country)\\n\\ncountry\\n\\nstring\\n\\ndefault:us\\n\\nCountry code for search results\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#body-location)\\n\\nlocation\\n\\nstring\\n\\nLocation parameter for search results\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#body-timeout)\\n\\ntimeout\\n\\ninteger\\n\\ndefault:60000\\n\\nTimeout in milliseconds\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#body-scrape-options)\\n\\nscrapeOptions\\n\\nobject\\n\\nOptions for scraping search results\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#body-scrape-options-formats)\\n\\nscrapeOptions.formats\\n\\nenum<string>\\\\[\\\\]\\n\\nFormats to include in the output\\n\\nAvailable options:\\n\\n`markdown`,\\n\\n`html`,\\n\\n`rawHtml`,\\n\\n`links`,\\n\\n`screenshot`,\\n\\n`screenshot@fullPage`,\\n\\n`extract`\\n\\n#### Response\\n\\n200\\n\\n200408500\\n\\napplication/json\\n\\nSuccessful response\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#response-success)\\n\\nsuccess\\n\\nboolean\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#response-data)\\n\\ndata\\n\\nobject\\\\[\\\\]\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#response-data-title)\\n\\ndata.title\\n\\nstring\\n\\nTitle from search result\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#response-data-description)\\n\\ndata.description\\n\\nstring\\n\\nDescription from search result\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#response-data-url)\\n\\ndata.url\\n\\nstring\\n\\nURL of the search result\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#response-data-markdown)\\n\\ndata.markdown\\n\\nstring \\\\| null\\n\\nMarkdown content if scraping was requested\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#response-data-html)\\n\\ndata.html\\n\\nstring \\\\| null\\n\\nHTML content if requested in formats\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#response-data-raw-html)\\n\\ndata.rawHtml\\n\\nstring \\\\| null\\n\\nRaw HTML content if requested in formats\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#response-data-links)\\n\\ndata.links\\n\\nstring\\\\[\\\\]\\n\\nLinks found if requested in formats\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#response-data-screenshot)\\n\\ndata.screenshot\\n\\nstring \\\\| null\\n\\nScreenshot URL if requested in formats\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#response-data-metadata)\\n\\ndata.metadata\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#response-data-metadata-title)\\n\\ndata.metadata.title\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#response-data-metadata-description)\\n\\ndata.metadata.description\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#response-data-metadata-source-url)\\n\\ndata.metadata.sourceURL\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#response-data-metadata-status-code)\\n\\ndata.metadata.statusCode\\n\\ninteger\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#response-data-metadata-error)\\n\\ndata.metadata.error\\n\\nstring \\\\| null\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/search#response-warning)\\n\\nwarning\\n\\nstring \\\\| null\\n\\nWarning message if any issues occurred\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/api-reference/endpoint/search.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/search)\\n\\n[Get Extract Status](https://docs.firecrawl.dev/api-reference/endpoint/extract-get) [Credit Usage](https://docs.firecrawl.dev/api-reference/endpoint/credit-usage)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/search \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"query\": \"<string>\",\\n  \"limit\": 5,\\n  \"tbs\": \"<string>\",\\n  \"lang\": \"en\",\\n  \"country\": \"us\",\\n  \"location\": \"<string>\",\\n  \"timeout\": 60000,\\n  \"scrapeOptions\": {}\\n}\\'\\n```\\n\\n200\\n\\n408\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"data\": [\\\\\\n    {\\\\\\n      \"title\": \"<string>\",\\\\\\n      \"description\": \"<string>\",\\\\\\n      \"url\": \"<string>\",\\\\\\n      \"markdown\": \"<string>\",\\\\\\n      \"html\": \"<string>\",\\\\\\n      \"rawHtml\": \"<string>\",\\\\\\n      \"links\": [\\\\\\n        \"<string>\"\\\\\\n      ],\\\\\\n      \"screenshot\": \"<string>\",\\\\\\n      \"metadata\": {\\\\\\n        \"title\": \"<string>\",\\\\\\n        \"description\": \"<string>\",\\\\\\n        \"sourceURL\": \"<string>\",\\\\\\n        \"statusCode\": 123,\\\\\\n        \"error\": \"<string>\"\\\\\\n      }\\\\\\n    }\\\\\\n  ],\\n  \"warning\": \"<string>\"\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/api-reference/introduction',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nUsing the API\\n\\nIntroduction\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\n## [\\u200b](https://docs.firecrawl.dev/api-reference/introduction\\\\#features)  Features\\n\\n[**Scrape** \\\\\\\\\\n\\\\\\\\\\nExtract content from any webpage in markdown or json format.](https://docs.firecrawl.dev/api-reference/endpoint/scrape) [**Crawl** \\\\\\\\\\n\\\\\\\\\\nCrawl entire websites, extract their content and metadata.](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post) [**Map** \\\\\\\\\\n\\\\\\\\\\nGet a complete list of URLs from any website quickly and reliably.](https://docs.firecrawl.dev/api-reference/endpoint/map) [**Extract** \\\\\\\\\\n\\\\\\\\\\nExtract structured data from entire webpages using natural language.](https://docs.firecrawl.dev/api-reference/endpoint/extract) [**Search** \\\\\\\\\\n\\\\\\\\\\nSearch the web and get full page content in any format.](https://docs.firecrawl.dev/api-reference/endpoint/search)\\n\\n## [\\u200b](https://docs.firecrawl.dev/api-reference/introduction\\\\#base-url)  Base URL\\n\\nAll requests contain the following base URL:\\n\\nCopy\\n\\n```bash\\nhttps://api.firecrawl.dev\\n\\n```\\n\\n## [\\u200b](https://docs.firecrawl.dev/api-reference/introduction\\\\#authentication)  Authentication\\n\\nFor authentication, itâ€™s required to include an Authorization header. The header should contain `Bearer fc-123456789`, where `fc-123456789` represents your API Key.\\n\\nCopy\\n\\n```bash\\nAuthorization: Bearer fc-123456789\\n\\n```\\n\\n\\u200b\\n\\n## [\\u200b](https://docs.firecrawl.dev/api-reference/introduction\\\\#response-codes)  Response codes\\n\\nFirecrawl employs conventional HTTP status codes to signify the outcome of your requests.\\n\\nTypically, 2xx HTTP status codes denote success, 4xx codes represent failures related to the user, and 5xx codes signal infrastructure problems.\\n\\n| Status | Description |\\n| --- | --- |\\n| 200 | Request was successful. |\\n| 400 | Verify the correctness of the parameters. |\\n| 401 | The API key was not provided. |\\n| 402 | Payment required |\\n| 404 | The requested resource could not be located. |\\n| 429 | The rate limit has been surpassed. |\\n| 5xx | Signifies a server error with Firecrawl. |\\n\\nRefer to the Error Codes section for a detailed explanation of all potential API errors.\\n\\n\\u200b\\n\\n## [\\u200b](https://docs.firecrawl.dev/api-reference/introduction\\\\#rate-limit)  Rate limit\\n\\nThe Firecrawl API has a rate limit to ensure the stability and reliability of the service. The rate limit is applied to all endpoints and is based on the number of requests made within a specific time frame.\\n\\nWhen you exceed the rate limit, you will receive a 429 response code.\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/api-reference/introduction.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/introduction)\\n\\n[Scrape](https://docs.firecrawl.dev/api-reference/endpoint/scrape)\\n\\nOn this page\\n\\n- [Features](https://docs.firecrawl.dev/api-reference/introduction#features)\\n- [Base URL](https://docs.firecrawl.dev/api-reference/introduction#base-url)\\n- [Authentication](https://docs.firecrawl.dev/api-reference/introduction#authentication)\\n- [Response codes](https://docs.firecrawl.dev/api-reference/introduction#response-codes)\\n- [Rate limit](https://docs.firecrawl.dev/api-reference/introduction#rate-limit)'},\n",
              " {'url': 'https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nDeep Research\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nGET\\n\\n/\\n\\ndeep-research\\n\\n/\\n\\n{id}\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request GET \\\\\\n  --url https://api.firecrawl.dev/v1/deep-research/{id} \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\n404\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"data\": {\\n    \"finalAnalysis\": \"<string>\",\\n    \"activities\": [\\\\\\n      {\\\\\\n        \"type\": \"<string>\",\\\\\\n        \"status\": \"<string>\",\\\\\\n        \"message\": \"<string>\",\\\\\\n        \"timestamp\": \"2023-11-07T05:31:56Z\",\\\\\\n        \"depth\": 123\\\\\\n      }\\\\\\n    ],\\n    \"sources\": [\\\\\\n      {\\\\\\n        \"url\": \"<string>\",\\\\\\n        \"title\": \"<string>\",\\\\\\n        \"description\": \"<string>\",\\\\\\n        \"favicon\": \"<string>\"\\\\\\n      }\\\\\\n    ],\\n    \"status\": \"processing\",\\n    \"error\": \"<string>\",\\n    \"expiresAt\": \"2023-11-07T05:31:56Z\",\\n    \"currentDepth\": 123,\\n    \"maxDepth\": 123,\\n    \"totalUrls\": 123\\n  }\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Path Parameters\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get#parameter-id)\\n\\nid\\n\\nstring\\n\\nrequired\\n\\nThe ID of the research job\\n\\n#### Response\\n\\n200\\n\\n200404\\n\\napplication/json\\n\\nSuccessful response\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get#response-success)\\n\\nsuccess\\n\\nboolean\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get#response-data)\\n\\ndata\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get#response-data-final-analysis)\\n\\ndata.finalAnalysis\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get#response-data-activities)\\n\\ndata.activities\\n\\nobject\\\\[\\\\]\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get#response-data-activities-type)\\n\\ndata.activities.type\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get#response-data-activities-status)\\n\\ndata.activities.status\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get#response-data-activities-message)\\n\\ndata.activities.message\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get#response-data-activities-timestamp)\\n\\ndata.activities.timestamp\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get#response-data-activities-depth)\\n\\ndata.activities.depth\\n\\ninteger\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get#response-data-sources)\\n\\ndata.sources\\n\\nobject\\\\[\\\\]\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get#response-data-sources-url)\\n\\ndata.sources.url\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get#response-data-sources-title)\\n\\ndata.sources.title\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get#response-data-sources-description)\\n\\ndata.sources.description\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get#response-data-sources-favicon)\\n\\ndata.sources.favicon\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get#response-data-status)\\n\\ndata.status\\n\\nenum<string>\\n\\nAvailable options:\\n\\n`processing`,\\n\\n`completed`,\\n\\n`failed`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get#response-data-error)\\n\\ndata.error\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get#response-data-expires-at)\\n\\ndata.expiresAt\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get#response-data-current-depth)\\n\\ndata.currentDepth\\n\\ninteger\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get#response-data-max-depth)\\n\\ndata.maxDepth\\n\\ninteger\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get#response-data-total-urls)\\n\\ndata.totalUrls\\n\\ninteger\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/api-reference/endpoint/deep-research-get.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/deep-research-get)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request GET \\\\\\n  --url https://api.firecrawl.dev/v1/deep-research/{id} \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\n404\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"data\": {\\n    \"finalAnalysis\": \"<string>\",\\n    \"activities\": [\\\\\\n      {\\\\\\n        \"type\": \"<string>\",\\\\\\n        \"status\": \"<string>\",\\\\\\n        \"message\": \"<string>\",\\\\\\n        \"timestamp\": \"2023-11-07T05:31:56Z\",\\\\\\n        \"depth\": 123\\\\\\n      }\\\\\\n    ],\\n    \"sources\": [\\\\\\n      {\\\\\\n        \"url\": \"<string>\",\\\\\\n        \"title\": \"<string>\",\\\\\\n        \"description\": \"<string>\",\\\\\\n        \"favicon\": \"<string>\"\\\\\\n      }\\\\\\n    ],\\n    \"status\": \"processing\",\\n    \"error\": \"<string>\",\\n    \"expiresAt\": \"2023-11-07T05:31:56Z\",\\n    \"currentDepth\": 123,\\n    \"maxDepth\": 123,\\n    \"totalUrls\": 123\\n  }\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nCrawl Endpoints\\n\\nCrawl\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nPOST\\n\\n/\\n\\ncrawl\\n\\nTry it\\n\\nPOST\\n\\nCrawl multiple URLs based on options\\n\\nPOST\\n\\n/\\n\\ncrawl\\n\\nSend\\n\\nCrawl multiple URLs based on options\\n\\nAuthorization\\n\\nbearerAuth\\n\\nAuthorization\\n\\nstring\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\nBearer\\n\\nBody\\n\\nurl\\n\\nstring\\n\\nrequired\\n\\nThe base URL to start crawling from\\n\\nexcludePaths\\n\\narray\\n\\nURL pathname regex patterns that exclude matching URLs from the crawl. For example, if you set \"excludePaths\": \\\\[\"blog/.\\\\*\"\\\\] for the base URL firecrawl.dev, any results matching that pattern will be excluded, such as [https://www.firecrawl.dev/blog/firecrawl-launch-week-1-recap](https://www.firecrawl.dev/blog/firecrawl-launch-week-1-recap).\\n\\nAdd an item\\n\\nincludePaths\\n\\narray\\n\\nURL pathname regex patterns that include matching URLs in the crawl. Only the paths that match the specified patterns will be included in the response. For example, if you set \"includePaths\": \\\\[\"blog/.\\\\*\"\\\\] for the base URL firecrawl.dev, only results matching that pattern will be included, such as [https://www.firecrawl.dev/blog/firecrawl-launch-week-1-recap](https://www.firecrawl.dev/blog/firecrawl-launch-week-1-recap).\\n\\nAdd an item\\n\\nmaxDepth\\n\\ninteger\\n\\nMaximum depth to crawl relative to the base URL. Basically, the max number of slashes the pathname of a scraped URL may contain.\\n\\nmaxDiscoveryDepth\\n\\ninteger\\n\\nMaximum depth to crawl based on discovery order. The root site and sitemapped pages has a discovery depth of 0. For example, if you set it to 1, and you set ignoreSitemap, you will only crawl the entered URL and all URLs that are linked on that page.\\n\\nignoreSitemap\\n\\nboolean\\n\\nIgnore the website sitemap when crawling\\n\\nselect ignoreSitemaptruefalse\\n\\nignoreQueryParameters\\n\\nboolean\\n\\nDo not re-scrape the same path with different (or none) query parameters\\n\\nselect ignoreQueryParameterstruefalse\\n\\nlimit\\n\\ninteger\\n\\nMaximum number of pages to crawl. Default limit is 10000.\\n\\nallowBackwardLinks\\n\\nboolean\\n\\nEnables the crawler to navigate from a specific URL to previously linked pages.\\n\\nselect allowBackwardLinkstruefalse\\n\\nallowExternalLinks\\n\\nboolean\\n\\nAllows the crawler to follow links to external websites.\\n\\nselect allowExternalLinkstruefalse\\n\\nwebhook\\n\\nobject\\n\\nA webhook specification object.\\n\\nwebhook.url\\n\\nstring\\n\\nrequired\\n\\nThe URL to send the webhook to. This will trigger for crawl started (crawl.started), every page crawled (crawl.page) and when the crawl is completed (crawl.completed or crawl.failed). The response will be the same as the `/scrape` endpoint.\\n\\nwebhook.headers\\n\\nobject\\n\\nHeaders to send to the webhook URL.\\n\\nAdd new property\\n\\nwebhook.metadata\\n\\nobject\\n\\nCustom metadata that will be included in all webhook payloads for this crawl\\n\\nAdd new property\\n\\nwebhook.events\\n\\narray\\n\\nType of events that should be sent to the webhook URL. (default: all)\\n\\nAdd an item\\n\\nAdd new property\\n\\nscrapeOptions\\n\\nobject\\n\\nscrapeOptions.formats\\n\\narray\\n\\nFormats to include in the output.\\n\\nAdd an item\\n\\nscrapeOptions.onlyMainContent\\n\\nboolean\\n\\nOnly return the main content of the page excluding headers, navs, footers, etc.\\n\\nselect onlyMainContenttruefalse\\n\\nscrapeOptions.includeTags\\n\\narray\\n\\nTags to include in the output.\\n\\nAdd an item\\n\\nscrapeOptions.excludeTags\\n\\narray\\n\\nTags to exclude from the output.\\n\\nAdd an item\\n\\nscrapeOptions.headers\\n\\nobject\\n\\nHeaders to send with the request. Can be used to send cookies, user-agent, etc.\\n\\nAdd new property\\n\\nscrapeOptions.waitFor\\n\\ninteger\\n\\nSpecify a delay in milliseconds before fetching the content, allowing the page sufficient time to load.\\n\\nscrapeOptions.mobile\\n\\nboolean\\n\\nSet to true if you want to emulate scraping from a mobile device. Useful for testing responsive pages and taking mobile screenshots.\\n\\nselect mobiletruefalse\\n\\nscrapeOptions.skipTlsVerification\\n\\nboolean\\n\\nSkip TLS certificate verification when making requests\\n\\nselect skipTlsVerificationtruefalse\\n\\nscrapeOptions.timeout\\n\\ninteger\\n\\nTimeout in milliseconds for the request\\n\\nscrapeOptions.jsonOptions\\n\\nobject\\n\\nExtract object\\n\\nscrapeOptions.jsonOptions.schema\\n\\nobject\\n\\nThe schema to use for the extraction (Optional)\\n\\nAdd new property\\n\\nscrapeOptions.jsonOptions.systemPrompt\\n\\nstring\\n\\nThe system prompt to use for the extraction (Optional)\\n\\nscrapeOptions.jsonOptions.prompt\\n\\nstring\\n\\nThe prompt to use for the extraction without a schema (Optional)\\n\\nAdd new property\\n\\nscrapeOptions.actions\\n\\narray\\n\\nActions to perform on the page before grabbing the content\\n\\nAdd an item\\n\\nscrapeOptions.location\\n\\nobject\\n\\nLocation settings for the request. When specified, this will use an appropriate proxy if available and emulate the corresponding language and timezone settings. Defaults to \\'US\\' if not specified.\\n\\nscrapeOptions.location.country\\n\\nstring\\n\\nISO 3166-1 alpha-2 country code (e.g., \\'US\\', \\'AU\\', \\'DE\\', \\'JP\\')\\n\\nscrapeOptions.location.languages\\n\\narray\\n\\nPreferred languages and locales for the request in order of priority. Defaults to the language of the specified location. See [https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Language](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Language)\\n\\nAdd an item\\n\\nAdd new property\\n\\nscrapeOptions.removeBase64Images\\n\\nboolean\\n\\nRemoves all base 64 images from the output, which may be overwhelmingly long. The image\\'s alt text remains in the output, but the URL is replaced with a placeholder.\\n\\nselect removeBase64Imagestruefalse\\n\\nscrapeOptions.blockAds\\n\\nboolean\\n\\nEnables ad-blocking and cookie popup blocking.\\n\\nselect blockAdstruefalse\\n\\nscrapeOptions.proxy\\n\\nenum<string>\\n\\nSpecifies the type of proxy to use.\\n\\n- **basic**: Proxies for scraping sites with none to basic anti-bot solutions. Fast and usually works.\\n- **stealth**: Stealth proxies for scraping sites with advanced anti-bot solutions. Slower, but more reliable on certain sites.\\n\\nIf you do not specify a proxy, Firecrawl will automatically attempt to determine which one you need based on the target site.\\n\\nselect proxybasicstealth\\n\\nAdd new property\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/crawl \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"maxDepth\": 10,\\n  \"ignoreSitemap\": false,\\n  \"ignoreQueryParameters\": false,\\n  \"limit\": 10000,\\n  \"allowBackwardLinks\": false,\\n  \"allowExternalLinks\": false,\\n  \"scrapeOptions\": {\\n    \"blockAds\": true\\n  }\\n}\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"id\": \"<string>\",\\n  \"url\": \"<string>\"\\n}\\n```\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/crawl \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"maxDepth\": 10,\\n  \"ignoreSitemap\": false,\\n  \"ignoreQueryParameters\": false,\\n  \"limit\": 10000,\\n  \"allowBackwardLinks\": false,\\n  \"allowExternalLinks\": false,\\n  \"scrapeOptions\": {\\n    \"blockAds\": true\\n  }\\n}\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"id\": \"<string>\",\\n  \"url\": \"<string>\"\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Body\\n\\napplication/json\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-url)\\n\\nurl\\n\\nstring\\n\\nrequired\\n\\nThe base URL to start crawling from\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-exclude-paths)\\n\\nexcludePaths\\n\\nstring\\\\[\\\\]\\n\\nURL pathname regex patterns that exclude matching URLs from the crawl. For example, if you set \"excludePaths\": \\\\[\"blog/.\\\\*\"\\\\] for the base URL firecrawl.dev, any results matching that pattern will be excluded, such as [https://www.firecrawl.dev/blog/firecrawl-launch-week-1-recap](https://www.firecrawl.dev/blog/firecrawl-launch-week-1-recap).\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-include-paths)\\n\\nincludePaths\\n\\nstring\\\\[\\\\]\\n\\nURL pathname regex patterns that include matching URLs in the crawl. Only the paths that match the specified patterns will be included in the response. For example, if you set \"includePaths\": \\\\[\"blog/.\\\\*\"\\\\] for the base URL firecrawl.dev, only results matching that pattern will be included, such as [https://www.firecrawl.dev/blog/firecrawl-launch-week-1-recap](https://www.firecrawl.dev/blog/firecrawl-launch-week-1-recap).\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-max-depth)\\n\\nmaxDepth\\n\\ninteger\\n\\ndefault:10\\n\\nMaximum depth to crawl relative to the base URL. Basically, the max number of slashes the pathname of a scraped URL may contain.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-max-discovery-depth)\\n\\nmaxDiscoveryDepth\\n\\ninteger\\n\\nMaximum depth to crawl based on discovery order. The root site and sitemapped pages has a discovery depth of 0. For example, if you set it to 1, and you set ignoreSitemap, you will only crawl the entered URL and all URLs that are linked on that page.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-ignore-sitemap)\\n\\nignoreSitemap\\n\\nboolean\\n\\ndefault:false\\n\\nIgnore the website sitemap when crawling\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-ignore-query-parameters)\\n\\nignoreQueryParameters\\n\\nboolean\\n\\ndefault:false\\n\\nDo not re-scrape the same path with different (or none) query parameters\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-limit)\\n\\nlimit\\n\\ninteger\\n\\ndefault:10000\\n\\nMaximum number of pages to crawl. Default limit is 10000.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-allow-backward-links)\\n\\nallowBackwardLinks\\n\\nboolean\\n\\ndefault:false\\n\\nEnables the crawler to navigate from a specific URL to previously linked pages.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-allow-external-links)\\n\\nallowExternalLinks\\n\\nboolean\\n\\ndefault:false\\n\\nAllows the crawler to follow links to external websites.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-webhook)\\n\\nwebhook\\n\\nobject\\n\\nA webhook specification object.\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-webhook-url)\\n\\nwebhook.url\\n\\nstring\\n\\nrequired\\n\\nThe URL to send the webhook to. This will trigger for crawl started (crawl.started), every page crawled (crawl.page) and when the crawl is completed (crawl.completed or crawl.failed). The response will be the same as the `/scrape` endpoint.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-webhook-headers)\\n\\nwebhook.headers\\n\\nobject\\n\\nHeaders to send to the webhook URL.\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-webhook-headers-key)\\n\\nwebhook.headers.{key}\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-webhook-metadata)\\n\\nwebhook.metadata\\n\\nobject\\n\\nCustom metadata that will be included in all webhook payloads for this crawl\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-webhook-events)\\n\\nwebhook.events\\n\\nenum<string>\\\\[\\\\]\\n\\nType of events that should be sent to the webhook URL. (default: all)\\n\\nAvailable options:\\n\\n`completed`,\\n\\n`page`,\\n\\n`failed`,\\n\\n`started`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options)\\n\\nscrapeOptions\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options-formats)\\n\\nscrapeOptions.formats\\n\\nenum<string>\\\\[\\\\]\\n\\nFormats to include in the output.\\n\\nAvailable options:\\n\\n`markdown`,\\n\\n`html`,\\n\\n`rawHtml`,\\n\\n`links`,\\n\\n`screenshot`,\\n\\n`screenshot@fullPage`,\\n\\n`json`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options-only-main-content)\\n\\nscrapeOptions.onlyMainContent\\n\\nboolean\\n\\ndefault:true\\n\\nOnly return the main content of the page excluding headers, navs, footers, etc.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options-include-tags)\\n\\nscrapeOptions.includeTags\\n\\nstring\\\\[\\\\]\\n\\nTags to include in the output.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options-exclude-tags)\\n\\nscrapeOptions.excludeTags\\n\\nstring\\\\[\\\\]\\n\\nTags to exclude from the output.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options-headers)\\n\\nscrapeOptions.headers\\n\\nobject\\n\\nHeaders to send with the request. Can be used to send cookies, user-agent, etc.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options-wait-for)\\n\\nscrapeOptions.waitFor\\n\\ninteger\\n\\ndefault:0\\n\\nSpecify a delay in milliseconds before fetching the content, allowing the page sufficient time to load.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options-mobile)\\n\\nscrapeOptions.mobile\\n\\nboolean\\n\\ndefault:false\\n\\nSet to true if you want to emulate scraping from a mobile device. Useful for testing responsive pages and taking mobile screenshots.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options-skip-tls-verification)\\n\\nscrapeOptions.skipTlsVerification\\n\\nboolean\\n\\ndefault:false\\n\\nSkip TLS certificate verification when making requests\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options-timeout)\\n\\nscrapeOptions.timeout\\n\\ninteger\\n\\ndefault:30000\\n\\nTimeout in milliseconds for the request\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options-json-options)\\n\\nscrapeOptions.jsonOptions\\n\\nobject\\n\\nExtract object\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options-json-options-schema)\\n\\nscrapeOptions.jsonOptions.schema\\n\\nobject\\n\\nThe schema to use for the extraction (Optional)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options-json-options-system-prompt)\\n\\nscrapeOptions.jsonOptions.systemPrompt\\n\\nstring\\n\\nThe system prompt to use for the extraction (Optional)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options-json-options-prompt)\\n\\nscrapeOptions.jsonOptions.prompt\\n\\nstring\\n\\nThe prompt to use for the extraction without a schema (Optional)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options-actions)\\n\\nscrapeOptions.actions\\n\\nobject\\\\[\\\\]\\n\\nActions to perform on the page before grabbing the content\\n\\n- Wait\\n- Screenshot\\n- Click\\n- Write text\\n- Press a key\\n- Scroll\\n- Scrape\\n- Execute JavaScript\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options-actions-type)\\n\\nscrapeOptions.actions.type\\n\\nenum<string>\\n\\nrequired\\n\\nWait for a specified amount of milliseconds\\n\\nAvailable options:\\n\\n`wait`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options-actions-milliseconds)\\n\\nscrapeOptions.actions.milliseconds\\n\\ninteger\\n\\nNumber of milliseconds to wait\\n\\nRequired range: `x >= 1`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options-actions-selector)\\n\\nscrapeOptions.actions.selector\\n\\nstring\\n\\nQuery selector to find the element by\\n\\nExample:\\n\\n`\"#my-element\"`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options-location)\\n\\nscrapeOptions.location\\n\\nobject\\n\\nLocation settings for the request. When specified, this will use an appropriate proxy if available and emulate the corresponding language and timezone settings. Defaults to \\'US\\' if not specified.\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options-location-country)\\n\\nscrapeOptions.location.country\\n\\nstring\\n\\ndefault:US\\n\\nISO 3166-1 alpha-2 country code (e.g., \\'US\\', \\'AU\\', \\'DE\\', \\'JP\\')\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options-location-languages)\\n\\nscrapeOptions.location.languages\\n\\nstring\\\\[\\\\]\\n\\nPreferred languages and locales for the request in order of priority. Defaults to the language of the specified location. See [https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Language](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Language)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options-remove-base64-images)\\n\\nscrapeOptions.removeBase64Images\\n\\nboolean\\n\\nRemoves all base 64 images from the output, which may be overwhelmingly long. The image\\'s alt text remains in the output, but the URL is replaced with a placeholder.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options-block-ads)\\n\\nscrapeOptions.blockAds\\n\\nboolean\\n\\ndefault:true\\n\\nEnables ad-blocking and cookie popup blocking.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#body-scrape-options-proxy)\\n\\nscrapeOptions.proxy\\n\\nenum<string>\\n\\nSpecifies the type of proxy to use.\\n\\n- **basic**: Proxies for scraping sites with none to basic anti-bot solutions. Fast and usually works.\\n- **stealth**: Stealth proxies for scraping sites with advanced anti-bot solutions. Slower, but more reliable on certain sites.\\n\\nIf you do not specify a proxy, Firecrawl will automatically attempt to determine which one you need based on the target site.\\n\\nAvailable options:\\n\\n`basic`,\\n\\n`stealth`\\n\\n#### Response\\n\\n200\\n\\n200402429500\\n\\napplication/json\\n\\nSuccessful response\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#response-success)\\n\\nsuccess\\n\\nboolean\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#response-id)\\n\\nid\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post?playground=open#response-url)\\n\\nurl\\n\\nstring\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/api-reference/endpoint/crawl-post.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/crawl-post)\\n\\n[Get Batch Scrape Errors](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get-errors) [Get Crawl Status](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/crawl \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"url\": \"<string>\",\\n  \"excludePaths\": [\\\\\\n    \"<string>\"\\\\\\n  ],\\n  \"includePaths\": [\\\\\\n    \"<string>\"\\\\\\n  ],\\n  \"maxDepth\": 10,\\n  \"maxDiscoveryDepth\": 123,\\n  \"ignoreSitemap\": false,\\n  \"ignoreQueryParameters\": false,\\n  \"limit\": 10000,\\n  \"allowBackwardLinks\": false,\\n  \"allowExternalLinks\": false,\\n  \"webhook\": {\\n    \"url\": \"<string>\",\\n    \"headers\": {},\\n    \"metadata\": {},\\n    \"events\": [\\\\\\n      \"completed\"\\\\\\n    ]\\n  },\\n  \"scrapeOptions\": {\\n    \"formats\": [\\\\\\n      \"markdown\"\\\\\\n    ],\\n    \"onlyMainContent\": true,\\n    \"includeTags\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"excludeTags\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"headers\": {},\\n    \"waitFor\": 0,\\n    \"mobile\": false,\\n    \"skipTlsVerification\": false,\\n    \"timeout\": 30000,\\n    \"jsonOptions\": {\\n      \"schema\": {},\\n      \"systemPrompt\": \"<string>\",\\n      \"prompt\": \"<string>\"\\n    },\\n    \"actions\": [\\\\\\n      {\\\\\\n        \"type\": \"wait\",\\\\\\n        \"milliseconds\": 2,\\\\\\n        \"selector\": \"#my-element\"\\\\\\n      }\\\\\\n    ],\\n    \"location\": {\\n      \"country\": \"US\",\\n      \"languages\": [\\\\\\n        \"en-US\"\\\\\\n      ]\\n    },\\n    \"removeBase64Images\": true,\\n    \"blockAds\": true,\\n    \"proxy\": \"basic\"\\n  }\\n}\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"id\": \"<string>\",\\n  \"url\": \"<string>\"\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get-errors',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nScrape Endpoints\\n\\nGet Batch Scrape Errors\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nGET\\n\\n/\\n\\nbatch\\n\\n/\\n\\nscrape\\n\\n/\\n\\n{id}\\n\\n/\\n\\nerrors\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request GET \\\\\\n  --url https://api.firecrawl.dev/v1/batch/scrape/{id}/errors \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"errors\": [\\\\\\n    {\\\\\\n      \"id\": \"<string>\",\\\\\\n      \"timestamp\": \"<string>\",\\\\\\n      \"url\": \"<string>\",\\\\\\n      \"error\": \"<string>\"\\\\\\n    }\\\\\\n  ],\\n  \"robotsBlocked\": [\\\\\\n    \"<string>\"\\\\\\n  ]\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get-errors#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Path Parameters\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get-errors#parameter-id)\\n\\nid\\n\\nstring\\n\\nrequired\\n\\nThe ID of the batch scrape job\\n\\n#### Response\\n\\n200\\n\\n200402429500\\n\\napplication/json\\n\\nSuccessful response\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get-errors#response-errors)\\n\\nerrors\\n\\nobject\\\\[\\\\]\\n\\nErrored scrape jobs and error details\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get-errors#response-errors-id)\\n\\nerrors.id\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get-errors#response-errors-timestamp)\\n\\nerrors.timestamp\\n\\nstring \\\\| null\\n\\nISO timestamp of failure\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get-errors#response-errors-url)\\n\\nerrors.url\\n\\nstring\\n\\nScraped URL\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get-errors#response-errors-error)\\n\\nerrors.error\\n\\nstring\\n\\nError message\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get-errors#response-robots-blocked)\\n\\nrobotsBlocked\\n\\nstring\\\\[\\\\]\\n\\nList of URLs that were attempted in scraping but were blocked by robots.txt\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/api-reference/endpoint/batch-scrape-get-errors.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/batch-scrape-get-errors)\\n\\n[Get Batch Scrape Status](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get) [Crawl](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request GET \\\\\\n  --url https://api.firecrawl.dev/v1/batch/scrape/{id}/errors \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"errors\": [\\\\\\n    {\\\\\\n      \"id\": \"<string>\",\\\\\\n      \"timestamp\": \"<string>\",\\\\\\n      \"url\": \"<string>\",\\\\\\n      \"error\": \"<string>\"\\\\\\n    }\\\\\\n  ],\\n  \"robotsBlocked\": [\\\\\\n    \"<string>\"\\\\\\n  ]\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/api-reference/endpoint/crawl-post',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nCrawl Endpoints\\n\\nCrawl\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nPOST\\n\\n/\\n\\ncrawl\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/crawl \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"url\": \"<string>\",\\n  \"excludePaths\": [\\\\\\n    \"<string>\"\\\\\\n  ],\\n  \"includePaths\": [\\\\\\n    \"<string>\"\\\\\\n  ],\\n  \"maxDepth\": 10,\\n  \"maxDiscoveryDepth\": 123,\\n  \"ignoreSitemap\": false,\\n  \"ignoreQueryParameters\": false,\\n  \"limit\": 10000,\\n  \"allowBackwardLinks\": false,\\n  \"allowExternalLinks\": false,\\n  \"webhook\": {\\n    \"url\": \"<string>\",\\n    \"headers\": {},\\n    \"metadata\": {},\\n    \"events\": [\\\\\\n      \"completed\"\\\\\\n    ]\\n  },\\n  \"scrapeOptions\": {\\n    \"formats\": [\\\\\\n      \"markdown\"\\\\\\n    ],\\n    \"onlyMainContent\": true,\\n    \"includeTags\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"excludeTags\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"headers\": {},\\n    \"waitFor\": 0,\\n    \"mobile\": false,\\n    \"skipTlsVerification\": false,\\n    \"timeout\": 30000,\\n    \"jsonOptions\": {\\n      \"schema\": {},\\n      \"systemPrompt\": \"<string>\",\\n      \"prompt\": \"<string>\"\\n    },\\n    \"actions\": [\\\\\\n      {\\\\\\n        \"type\": \"wait\",\\\\\\n        \"milliseconds\": 2,\\\\\\n        \"selector\": \"#my-element\"\\\\\\n      }\\\\\\n    ],\\n    \"location\": {\\n      \"country\": \"US\",\\n      \"languages\": [\\\\\\n        \"en-US\"\\\\\\n      ]\\n    },\\n    \"removeBase64Images\": true,\\n    \"blockAds\": true,\\n    \"proxy\": \"basic\"\\n  }\\n}\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"id\": \"<string>\",\\n  \"url\": \"<string>\"\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Body\\n\\napplication/json\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-url)\\n\\nurl\\n\\nstring\\n\\nrequired\\n\\nThe base URL to start crawling from\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-exclude-paths)\\n\\nexcludePaths\\n\\nstring\\\\[\\\\]\\n\\nURL pathname regex patterns that exclude matching URLs from the crawl. For example, if you set \"excludePaths\": \\\\[\"blog/.\\\\*\"\\\\] for the base URL firecrawl.dev, any results matching that pattern will be excluded, such as [https://www.firecrawl.dev/blog/firecrawl-launch-week-1-recap](https://www.firecrawl.dev/blog/firecrawl-launch-week-1-recap).\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-include-paths)\\n\\nincludePaths\\n\\nstring\\\\[\\\\]\\n\\nURL pathname regex patterns that include matching URLs in the crawl. Only the paths that match the specified patterns will be included in the response. For example, if you set \"includePaths\": \\\\[\"blog/.\\\\*\"\\\\] for the base URL firecrawl.dev, only results matching that pattern will be included, such as [https://www.firecrawl.dev/blog/firecrawl-launch-week-1-recap](https://www.firecrawl.dev/blog/firecrawl-launch-week-1-recap).\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-max-depth)\\n\\nmaxDepth\\n\\ninteger\\n\\ndefault:10\\n\\nMaximum depth to crawl relative to the base URL. Basically, the max number of slashes the pathname of a scraped URL may contain.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-max-discovery-depth)\\n\\nmaxDiscoveryDepth\\n\\ninteger\\n\\nMaximum depth to crawl based on discovery order. The root site and sitemapped pages has a discovery depth of 0. For example, if you set it to 1, and you set ignoreSitemap, you will only crawl the entered URL and all URLs that are linked on that page.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-ignore-sitemap)\\n\\nignoreSitemap\\n\\nboolean\\n\\ndefault:false\\n\\nIgnore the website sitemap when crawling\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-ignore-query-parameters)\\n\\nignoreQueryParameters\\n\\nboolean\\n\\ndefault:false\\n\\nDo not re-scrape the same path with different (or none) query parameters\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-limit)\\n\\nlimit\\n\\ninteger\\n\\ndefault:10000\\n\\nMaximum number of pages to crawl. Default limit is 10000.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-allow-backward-links)\\n\\nallowBackwardLinks\\n\\nboolean\\n\\ndefault:false\\n\\nEnables the crawler to navigate from a specific URL to previously linked pages.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-allow-external-links)\\n\\nallowExternalLinks\\n\\nboolean\\n\\ndefault:false\\n\\nAllows the crawler to follow links to external websites.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-webhook)\\n\\nwebhook\\n\\nobject\\n\\nA webhook specification object.\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-webhook-url)\\n\\nwebhook.url\\n\\nstring\\n\\nrequired\\n\\nThe URL to send the webhook to. This will trigger for crawl started (crawl.started), every page crawled (crawl.page) and when the crawl is completed (crawl.completed or crawl.failed). The response will be the same as the `/scrape` endpoint.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-webhook-headers)\\n\\nwebhook.headers\\n\\nobject\\n\\nHeaders to send to the webhook URL.\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-webhook-headers-key)\\n\\nwebhook.headers.{key}\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-webhook-metadata)\\n\\nwebhook.metadata\\n\\nobject\\n\\nCustom metadata that will be included in all webhook payloads for this crawl\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-webhook-events)\\n\\nwebhook.events\\n\\nenum<string>\\\\[\\\\]\\n\\nType of events that should be sent to the webhook URL. (default: all)\\n\\nAvailable options:\\n\\n`completed`,\\n\\n`page`,\\n\\n`failed`,\\n\\n`started`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options)\\n\\nscrapeOptions\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options-formats)\\n\\nscrapeOptions.formats\\n\\nenum<string>\\\\[\\\\]\\n\\nFormats to include in the output.\\n\\nAvailable options:\\n\\n`markdown`,\\n\\n`html`,\\n\\n`rawHtml`,\\n\\n`links`,\\n\\n`screenshot`,\\n\\n`screenshot@fullPage`,\\n\\n`json`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options-only-main-content)\\n\\nscrapeOptions.onlyMainContent\\n\\nboolean\\n\\ndefault:true\\n\\nOnly return the main content of the page excluding headers, navs, footers, etc.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options-include-tags)\\n\\nscrapeOptions.includeTags\\n\\nstring\\\\[\\\\]\\n\\nTags to include in the output.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options-exclude-tags)\\n\\nscrapeOptions.excludeTags\\n\\nstring\\\\[\\\\]\\n\\nTags to exclude from the output.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options-headers)\\n\\nscrapeOptions.headers\\n\\nobject\\n\\nHeaders to send with the request. Can be used to send cookies, user-agent, etc.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options-wait-for)\\n\\nscrapeOptions.waitFor\\n\\ninteger\\n\\ndefault:0\\n\\nSpecify a delay in milliseconds before fetching the content, allowing the page sufficient time to load.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options-mobile)\\n\\nscrapeOptions.mobile\\n\\nboolean\\n\\ndefault:false\\n\\nSet to true if you want to emulate scraping from a mobile device. Useful for testing responsive pages and taking mobile screenshots.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options-skip-tls-verification)\\n\\nscrapeOptions.skipTlsVerification\\n\\nboolean\\n\\ndefault:false\\n\\nSkip TLS certificate verification when making requests\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options-timeout)\\n\\nscrapeOptions.timeout\\n\\ninteger\\n\\ndefault:30000\\n\\nTimeout in milliseconds for the request\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options-json-options)\\n\\nscrapeOptions.jsonOptions\\n\\nobject\\n\\nExtract object\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options-json-options-schema)\\n\\nscrapeOptions.jsonOptions.schema\\n\\nobject\\n\\nThe schema to use for the extraction (Optional)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options-json-options-system-prompt)\\n\\nscrapeOptions.jsonOptions.systemPrompt\\n\\nstring\\n\\nThe system prompt to use for the extraction (Optional)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options-json-options-prompt)\\n\\nscrapeOptions.jsonOptions.prompt\\n\\nstring\\n\\nThe prompt to use for the extraction without a schema (Optional)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options-actions)\\n\\nscrapeOptions.actions\\n\\nobject\\\\[\\\\]\\n\\nActions to perform on the page before grabbing the content\\n\\n- Wait\\n- Screenshot\\n- Click\\n- Write text\\n- Press a key\\n- Scroll\\n- Scrape\\n- Execute JavaScript\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options-actions-type)\\n\\nscrapeOptions.actions.type\\n\\nenum<string>\\n\\nrequired\\n\\nWait for a specified amount of milliseconds\\n\\nAvailable options:\\n\\n`wait`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options-actions-milliseconds)\\n\\nscrapeOptions.actions.milliseconds\\n\\ninteger\\n\\nNumber of milliseconds to wait\\n\\nRequired range: `x >= 1`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options-actions-selector)\\n\\nscrapeOptions.actions.selector\\n\\nstring\\n\\nQuery selector to find the element by\\n\\nExample:\\n\\n`\"#my-element\"`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options-location)\\n\\nscrapeOptions.location\\n\\nobject\\n\\nLocation settings for the request. When specified, this will use an appropriate proxy if available and emulate the corresponding language and timezone settings. Defaults to \\'US\\' if not specified.\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options-location-country)\\n\\nscrapeOptions.location.country\\n\\nstring\\n\\ndefault:US\\n\\nISO 3166-1 alpha-2 country code (e.g., \\'US\\', \\'AU\\', \\'DE\\', \\'JP\\')\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options-location-languages)\\n\\nscrapeOptions.location.languages\\n\\nstring\\\\[\\\\]\\n\\nPreferred languages and locales for the request in order of priority. Defaults to the language of the specified location. See [https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Language](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Language)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options-remove-base64-images)\\n\\nscrapeOptions.removeBase64Images\\n\\nboolean\\n\\nRemoves all base 64 images from the output, which may be overwhelmingly long. The image\\'s alt text remains in the output, but the URL is replaced with a placeholder.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options-block-ads)\\n\\nscrapeOptions.blockAds\\n\\nboolean\\n\\ndefault:true\\n\\nEnables ad-blocking and cookie popup blocking.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#body-scrape-options-proxy)\\n\\nscrapeOptions.proxy\\n\\nenum<string>\\n\\nSpecifies the type of proxy to use.\\n\\n- **basic**: Proxies for scraping sites with none to basic anti-bot solutions. Fast and usually works.\\n- **stealth**: Stealth proxies for scraping sites with advanced anti-bot solutions. Slower, but more reliable on certain sites.\\n\\nIf you do not specify a proxy, Firecrawl will automatically attempt to determine which one you need based on the target site.\\n\\nAvailable options:\\n\\n`basic`,\\n\\n`stealth`\\n\\n#### Response\\n\\n200\\n\\n200402429500\\n\\napplication/json\\n\\nSuccessful response\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#response-success)\\n\\nsuccess\\n\\nboolean\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#response-id)\\n\\nid\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#response-url)\\n\\nurl\\n\\nstring\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/api-reference/endpoint/crawl-post.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/crawl-post)\\n\\n[Get Batch Scrape Errors](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get-errors) [Get Crawl Status](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/crawl \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"url\": \"<string>\",\\n  \"excludePaths\": [\\\\\\n    \"<string>\"\\\\\\n  ],\\n  \"includePaths\": [\\\\\\n    \"<string>\"\\\\\\n  ],\\n  \"maxDepth\": 10,\\n  \"maxDiscoveryDepth\": 123,\\n  \"ignoreSitemap\": false,\\n  \"ignoreQueryParameters\": false,\\n  \"limit\": 10000,\\n  \"allowBackwardLinks\": false,\\n  \"allowExternalLinks\": false,\\n  \"webhook\": {\\n    \"url\": \"<string>\",\\n    \"headers\": {},\\n    \"metadata\": {},\\n    \"events\": [\\\\\\n      \"completed\"\\\\\\n    ]\\n  },\\n  \"scrapeOptions\": {\\n    \"formats\": [\\\\\\n      \"markdown\"\\\\\\n    ],\\n    \"onlyMainContent\": true,\\n    \"includeTags\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"excludeTags\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"headers\": {},\\n    \"waitFor\": 0,\\n    \"mobile\": false,\\n    \"skipTlsVerification\": false,\\n    \"timeout\": 30000,\\n    \"jsonOptions\": {\\n      \"schema\": {},\\n      \"systemPrompt\": \"<string>\",\\n      \"prompt\": \"<string>\"\\n    },\\n    \"actions\": [\\\\\\n      {\\\\\\n        \"type\": \"wait\",\\\\\\n        \"milliseconds\": 2,\\\\\\n        \"selector\": \"#my-element\"\\\\\\n      }\\\\\\n    ],\\n    \"location\": {\\n      \"country\": \"US\",\\n      \"languages\": [\\\\\\n        \"en-US\"\\\\\\n      ]\\n    },\\n    \"removeBase64Images\": true,\\n    \"blockAds\": true,\\n    \"proxy\": \"basic\"\\n  }\\n}\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"id\": \"<string>\",\\n  \"url\": \"<string>\"\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/api-reference/introduction',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nUsing the API\\n\\nIntroduction\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\n## [\\u200b](https://docs.firecrawl.dev/api-reference/introduction\\\\#features)  Features\\n\\n[**Scrape** \\\\\\\\\\n\\\\\\\\\\nExtract content from any webpage in markdown or json format.](https://docs.firecrawl.dev/api-reference/endpoint/scrape) [**Crawl** \\\\\\\\\\n\\\\\\\\\\nCrawl entire websites, extract their content and metadata.](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post) [**Map** \\\\\\\\\\n\\\\\\\\\\nGet a complete list of URLs from any website quickly and reliably.](https://docs.firecrawl.dev/api-reference/endpoint/map) [**Extract** \\\\\\\\\\n\\\\\\\\\\nExtract structured data from entire webpages using natural language.](https://docs.firecrawl.dev/api-reference/endpoint/extract) [**Search** \\\\\\\\\\n\\\\\\\\\\nSearch the web and get full page content in any format.](https://docs.firecrawl.dev/api-reference/endpoint/search)\\n\\n## [\\u200b](https://docs.firecrawl.dev/api-reference/introduction\\\\#base-url)  Base URL\\n\\nAll requests contain the following base URL:\\n\\nCopy\\n\\n```bash\\nhttps://api.firecrawl.dev\\n\\n```\\n\\n## [\\u200b](https://docs.firecrawl.dev/api-reference/introduction\\\\#authentication)  Authentication\\n\\nFor authentication, itâ€™s required to include an Authorization header. The header should contain `Bearer fc-123456789`, where `fc-123456789` represents your API Key.\\n\\nCopy\\n\\n```bash\\nAuthorization: Bearer fc-123456789\\n\\n```\\n\\n\\u200b\\n\\n## [\\u200b](https://docs.firecrawl.dev/api-reference/introduction\\\\#response-codes)  Response codes\\n\\nFirecrawl employs conventional HTTP status codes to signify the outcome of your requests.\\n\\nTypically, 2xx HTTP status codes denote success, 4xx codes represent failures related to the user, and 5xx codes signal infrastructure problems.\\n\\n| Status | Description |\\n| --- | --- |\\n| 200 | Request was successful. |\\n| 400 | Verify the correctness of the parameters. |\\n| 401 | The API key was not provided. |\\n| 402 | Payment required |\\n| 404 | The requested resource could not be located. |\\n| 429 | The rate limit has been surpassed. |\\n| 5xx | Signifies a server error with Firecrawl. |\\n\\nRefer to the Error Codes section for a detailed explanation of all potential API errors.\\n\\n\\u200b\\n\\n## [\\u200b](https://docs.firecrawl.dev/api-reference/introduction\\\\#rate-limit)  Rate limit\\n\\nThe Firecrawl API has a rate limit to ensure the stability and reliability of the service. The rate limit is applied to all endpoints and is based on the number of requests made within a specific time frame.\\n\\nWhen you exceed the rate limit, you will receive a 429 response code.\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/api-reference/introduction.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/introduction)\\n\\n[Scrape](https://docs.firecrawl.dev/api-reference/endpoint/scrape)\\n\\nOn this page\\n\\n- [Features](https://docs.firecrawl.dev/api-reference/introduction#features)\\n- [Base URL](https://docs.firecrawl.dev/api-reference/introduction#base-url)\\n- [Authentication](https://docs.firecrawl.dev/api-reference/introduction#authentication)\\n- [Response codes](https://docs.firecrawl.dev/api-reference/introduction#response-codes)\\n- [Rate limit](https://docs.firecrawl.dev/api-reference/introduction#rate-limit)'},\n",
              " {'url': 'https://docs.firecrawl.dev/api-reference/endpoint/map?playground=open',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nMap Endpoints\\n\\nMap\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nPOST\\n\\n/\\n\\nmap\\n\\nTry it\\n\\nPOST\\n\\nMap multiple URLs based on options\\n\\nPOST\\n\\n/\\n\\nmap\\n\\nSend\\n\\nMap multiple URLs based on options\\n\\nAuthorization\\n\\nbearerAuth\\n\\nAuthorization\\n\\nstring\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\nBearer\\n\\nBody\\n\\nurl\\n\\nstring\\n\\nrequired\\n\\nThe base URL to start crawling from\\n\\nsearch\\n\\nstring\\n\\nSearch query to use for mapping. During the Alpha phase, the \\'smart\\' part of the search functionality is limited to 1000 search results. However, if map finds more results, there is no limit applied.\\n\\nignoreSitemap\\n\\nboolean\\n\\nIgnore the website sitemap when crawling.\\n\\nselect ignoreSitemaptruefalse\\n\\nsitemapOnly\\n\\nboolean\\n\\nOnly return links found in the website sitemap\\n\\nselect sitemapOnlytruefalse\\n\\nincludeSubdomains\\n\\nboolean\\n\\nInclude subdomains of the website\\n\\nselect includeSubdomainstruefalse\\n\\nlimit\\n\\ninteger\\n\\nMaximum number of links to return\\n\\ntimeout\\n\\ninteger\\n\\nTimeout in milliseconds. There is no timeout by default.\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/map \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"ignoreSitemap\": true,\\n  \"sitemapOnly\": false,\\n  \"includeSubdomains\": false,\\n  \"limit\": 5000\\n}\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"links\": [\\\\\\n    \"<string>\"\\\\\\n  ]\\n}\\n```\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/map \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"ignoreSitemap\": true,\\n  \"sitemapOnly\": false,\\n  \"includeSubdomains\": false,\\n  \"limit\": 5000\\n}\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"links\": [\\\\\\n    \"<string>\"\\\\\\n  ]\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/map?playground=open#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Body\\n\\napplication/json\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/map?playground=open#body-url)\\n\\nurl\\n\\nstring\\n\\nrequired\\n\\nThe base URL to start crawling from\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/map?playground=open#body-search)\\n\\nsearch\\n\\nstring\\n\\nSearch query to use for mapping. During the Alpha phase, the \\'smart\\' part of the search functionality is limited to 1000 search results. However, if map finds more results, there is no limit applied.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/map?playground=open#body-ignore-sitemap)\\n\\nignoreSitemap\\n\\nboolean\\n\\ndefault:true\\n\\nIgnore the website sitemap when crawling.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/map?playground=open#body-sitemap-only)\\n\\nsitemapOnly\\n\\nboolean\\n\\ndefault:false\\n\\nOnly return links found in the website sitemap\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/map?playground=open#body-include-subdomains)\\n\\nincludeSubdomains\\n\\nboolean\\n\\ndefault:false\\n\\nInclude subdomains of the website\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/map?playground=open#body-limit)\\n\\nlimit\\n\\ninteger\\n\\ndefault:5000\\n\\nMaximum number of links to return\\n\\nRequired range: `x <= 5000`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/map?playground=open#body-timeout)\\n\\ntimeout\\n\\ninteger\\n\\nTimeout in milliseconds. There is no timeout by default.\\n\\n#### Response\\n\\n200\\n\\n200402429500\\n\\napplication/json\\n\\nSuccessful response\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/map?playground=open#response-success)\\n\\nsuccess\\n\\nboolean\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/map?playground=open#response-links)\\n\\nlinks\\n\\nstring\\\\[\\\\]\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/api-reference/endpoint/map.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/map)\\n\\n[Get Crawl Errors](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get-errors) [Extract](https://docs.firecrawl.dev/api-reference/endpoint/extract)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/map \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"url\": \"<string>\",\\n  \"search\": \"<string>\",\\n  \"ignoreSitemap\": true,\\n  \"sitemapOnly\": false,\\n  \"includeSubdomains\": false,\\n  \"limit\": 5000,\\n  \"timeout\": 123\\n}\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"links\": [\\\\\\n    \"<string>\"\\\\\\n  ]\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/v0/api-reference/endpoint/llm-extract',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/v0/api-reference/endpoint/llm-extract.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/v0/api-reference/endpoint/llm-extract)'},\n",
              " {'url': 'https://docs.firecrawl.dev/api-reference/endpoint/crawl-get-errors',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nCrawl Endpoints\\n\\nGet Crawl Errors\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nGET\\n\\n/\\n\\ncrawl\\n\\n/\\n\\n{id}\\n\\n/\\n\\nerrors\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request GET \\\\\\n  --url https://api.firecrawl.dev/v1/crawl/{id}/errors \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"errors\": [\\\\\\n    {\\\\\\n      \"id\": \"<string>\",\\\\\\n      \"timestamp\": \"<string>\",\\\\\\n      \"url\": \"<string>\",\\\\\\n      \"error\": \"<string>\"\\\\\\n    }\\\\\\n  ],\\n  \"robotsBlocked\": [\\\\\\n    \"<string>\"\\\\\\n  ]\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get-errors#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Path Parameters\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get-errors#parameter-id)\\n\\nid\\n\\nstring\\n\\nrequired\\n\\nThe ID of the crawl job\\n\\n#### Response\\n\\n200\\n\\n200402429500\\n\\napplication/json\\n\\nSuccessful response\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get-errors#response-errors)\\n\\nerrors\\n\\nobject\\\\[\\\\]\\n\\nErrored scrape jobs and error details\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get-errors#response-errors-id)\\n\\nerrors.id\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get-errors#response-errors-timestamp)\\n\\nerrors.timestamp\\n\\nstring \\\\| null\\n\\nISO timestamp of failure\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get-errors#response-errors-url)\\n\\nerrors.url\\n\\nstring\\n\\nScraped URL\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get-errors#response-errors-error)\\n\\nerrors.error\\n\\nstring\\n\\nError message\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get-errors#response-robots-blocked)\\n\\nrobotsBlocked\\n\\nstring\\\\[\\\\]\\n\\nList of URLs that were attempted in scraping but were blocked by robots.txt\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/api-reference/endpoint/crawl-get-errors.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/crawl-get-errors)\\n\\n[Cancel Crawl](https://docs.firecrawl.dev/api-reference/endpoint/crawl-delete) [Map](https://docs.firecrawl.dev/api-reference/endpoint/map)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request GET \\\\\\n  --url https://api.firecrawl.dev/v1/crawl/{id}/errors \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"errors\": [\\\\\\n    {\\\\\\n      \"id\": \"<string>\",\\\\\\n      \"timestamp\": \"<string>\",\\\\\\n      \"url\": \"<string>\",\\\\\\n      \"error\": \"<string>\"\\\\\\n    }\\\\\\n  ],\\n  \"robotsBlocked\": [\\\\\\n    \"<string>\"\\\\\\n  ]\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/api-reference/endpoint/scrape',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nScrape Endpoints\\n\\nScrape\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nPOST\\n\\n/\\n\\nscrape\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/scrape \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"url\": \"<string>\",\\n  \"formats\": [\\\\\\n    \"markdown\"\\\\\\n  ],\\n  \"onlyMainContent\": true,\\n  \"includeTags\": [\\\\\\n    \"<string>\"\\\\\\n  ],\\n  \"excludeTags\": [\\\\\\n    \"<string>\"\\\\\\n  ],\\n  \"headers\": {},\\n  \"waitFor\": 0,\\n  \"mobile\": false,\\n  \"skipTlsVerification\": false,\\n  \"timeout\": 30000,\\n  \"jsonOptions\": {\\n    \"schema\": {},\\n    \"systemPrompt\": \"<string>\",\\n    \"prompt\": \"<string>\"\\n  },\\n  \"actions\": [\\\\\\n    {\\\\\\n      \"type\": \"wait\",\\\\\\n      \"milliseconds\": 2,\\\\\\n      \"selector\": \"#my-element\"\\\\\\n    }\\\\\\n  ],\\n  \"location\": {\\n    \"country\": \"US\",\\n    \"languages\": [\\\\\\n      \"en-US\"\\\\\\n    ]\\n  },\\n  \"removeBase64Images\": true,\\n  \"blockAds\": true,\\n  \"proxy\": \"basic\"\\n}\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"data\": {\\n    \"markdown\": \"<string>\",\\n    \"html\": \"<string>\",\\n    \"rawHtml\": \"<string>\",\\n    \"screenshot\": \"<string>\",\\n    \"links\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"actions\": {\\n      \"screenshots\": [\\\\\\n        \"<string>\"\\\\\\n      ]\\n    },\\n    \"metadata\": {\\n      \"title\": \"<string>\",\\n      \"description\": \"<string>\",\\n      \"language\": \"<string>\",\\n      \"sourceURL\": \"<string>\",\\n      \"<any other metadata> \": \"<string>\",\\n      \"statusCode\": 123,\\n      \"error\": \"<string>\"\\n    },\\n    \"llm_extraction\": {},\\n    \"warning\": \"<string>\"\\n  }\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Body\\n\\napplication/json\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-url)\\n\\nurl\\n\\nstring\\n\\nrequired\\n\\nThe URL to scrape\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-formats)\\n\\nformats\\n\\nenum<string>\\\\[\\\\]\\n\\nFormats to include in the output.\\n\\nAvailable options:\\n\\n`markdown`,\\n\\n`html`,\\n\\n`rawHtml`,\\n\\n`links`,\\n\\n`screenshot`,\\n\\n`screenshot@fullPage`,\\n\\n`json`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-only-main-content)\\n\\nonlyMainContent\\n\\nboolean\\n\\ndefault:true\\n\\nOnly return the main content of the page excluding headers, navs, footers, etc.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-include-tags)\\n\\nincludeTags\\n\\nstring\\\\[\\\\]\\n\\nTags to include in the output.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-exclude-tags)\\n\\nexcludeTags\\n\\nstring\\\\[\\\\]\\n\\nTags to exclude from the output.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-headers)\\n\\nheaders\\n\\nobject\\n\\nHeaders to send with the request. Can be used to send cookies, user-agent, etc.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-wait-for)\\n\\nwaitFor\\n\\ninteger\\n\\ndefault:0\\n\\nSpecify a delay in milliseconds before fetching the content, allowing the page sufficient time to load.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-mobile)\\n\\nmobile\\n\\nboolean\\n\\ndefault:false\\n\\nSet to true if you want to emulate scraping from a mobile device. Useful for testing responsive pages and taking mobile screenshots.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-skip-tls-verification)\\n\\nskipTlsVerification\\n\\nboolean\\n\\ndefault:false\\n\\nSkip TLS certificate verification when making requests\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-timeout)\\n\\ntimeout\\n\\ninteger\\n\\ndefault:30000\\n\\nTimeout in milliseconds for the request\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-json-options)\\n\\njsonOptions\\n\\nobject\\n\\nExtract object\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-json-options-schema)\\n\\njsonOptions.schema\\n\\nobject\\n\\nThe schema to use for the extraction (Optional)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-json-options-system-prompt)\\n\\njsonOptions.systemPrompt\\n\\nstring\\n\\nThe system prompt to use for the extraction (Optional)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-json-options-prompt)\\n\\njsonOptions.prompt\\n\\nstring\\n\\nThe prompt to use for the extraction without a schema (Optional)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-actions)\\n\\nactions\\n\\nobject\\\\[\\\\]\\n\\nActions to perform on the page before grabbing the content\\n\\n- Wait\\n- Screenshot\\n- Click\\n- Write text\\n- Press a key\\n- Scroll\\n- Scrape\\n- Execute JavaScript\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-actions-type)\\n\\nactions.type\\n\\nenum<string>\\n\\nrequired\\n\\nWait for a specified amount of milliseconds\\n\\nAvailable options:\\n\\n`wait`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-actions-milliseconds)\\n\\nactions.milliseconds\\n\\ninteger\\n\\nNumber of milliseconds to wait\\n\\nRequired range: `x >= 1`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-actions-selector)\\n\\nactions.selector\\n\\nstring\\n\\nQuery selector to find the element by\\n\\nExample:\\n\\n`\"#my-element\"`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-location)\\n\\nlocation\\n\\nobject\\n\\nLocation settings for the request. When specified, this will use an appropriate proxy if available and emulate the corresponding language and timezone settings. Defaults to \\'US\\' if not specified.\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-location-country)\\n\\nlocation.country\\n\\nstring\\n\\ndefault:US\\n\\nISO 3166-1 alpha-2 country code (e.g., \\'US\\', \\'AU\\', \\'DE\\', \\'JP\\')\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-location-languages)\\n\\nlocation.languages\\n\\nstring\\\\[\\\\]\\n\\nPreferred languages and locales for the request in order of priority. Defaults to the language of the specified location. See [https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Language](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Language)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-remove-base64-images)\\n\\nremoveBase64Images\\n\\nboolean\\n\\nRemoves all base 64 images from the output, which may be overwhelmingly long. The image\\'s alt text remains in the output, but the URL is replaced with a placeholder.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-block-ads)\\n\\nblockAds\\n\\nboolean\\n\\ndefault:true\\n\\nEnables ad-blocking and cookie popup blocking.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-proxy)\\n\\nproxy\\n\\nenum<string>\\n\\nSpecifies the type of proxy to use.\\n\\n- **basic**: Proxies for scraping sites with none to basic anti-bot solutions. Fast and usually works.\\n- **stealth**: Stealth proxies for scraping sites with advanced anti-bot solutions. Slower, but more reliable on certain sites.\\n\\nIf you do not specify a proxy, Firecrawl will automatically attempt to determine which one you need based on the target site.\\n\\nAvailable options:\\n\\n`basic`,\\n\\n`stealth`\\n\\n#### Response\\n\\n200\\n\\n200402429500\\n\\napplication/json\\n\\nSuccessful response\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-success)\\n\\nsuccess\\n\\nboolean\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data)\\n\\ndata\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-markdown)\\n\\ndata.markdown\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-html)\\n\\ndata.html\\n\\nstring \\\\| null\\n\\nHTML version of the content on page if `html` is in `formats`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-raw-html)\\n\\ndata.rawHtml\\n\\nstring \\\\| null\\n\\nRaw HTML content of the page if `rawHtml` is in `formats`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-screenshot)\\n\\ndata.screenshot\\n\\nstring \\\\| null\\n\\nScreenshot of the page if `screenshot` is in `formats`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-links)\\n\\ndata.links\\n\\nstring\\\\[\\\\]\\n\\nList of links on the page if `links` is in `formats`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-actions)\\n\\ndata.actions\\n\\nobject \\\\| null\\n\\nResults of the actions specified in the `actions` parameter. Only present if the `actions` parameter was provided in the request\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-actions-screenshots)\\n\\ndata.actions.screenshots\\n\\nstring\\\\[\\\\]\\n\\nScreenshot URLs, in the same order as the screenshot actions provided.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-metadata)\\n\\ndata.metadata\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-metadata-title)\\n\\ndata.metadata.title\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-metadata-description)\\n\\ndata.metadata.description\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-metadata-language)\\n\\ndata.metadata.language\\n\\nstring \\\\| null\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-metadata-source-url)\\n\\ndata.metadata.sourceURL\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-metadata-any-other-metadata)\\n\\ndata.metadata.<any other metadata>\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-metadata-status-code)\\n\\ndata.metadata.statusCode\\n\\ninteger\\n\\nThe status code of the page\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-metadata-error)\\n\\ndata.metadata.error\\n\\nstring \\\\| null\\n\\nThe error message of the page\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-llm-extraction)\\n\\ndata.llm\\\\_extraction\\n\\nobject \\\\| null\\n\\nDisplayed when using LLM Extraction. Extracted data from the page following the schema defined.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-warning)\\n\\ndata.warning\\n\\nstring \\\\| null\\n\\nCan be displayed when using LLM Extraction. Warning message will let you know any issues with the extraction.\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/api-reference/endpoint/scrape.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/scrape)\\n\\n[Introduction](https://docs.firecrawl.dev/api-reference/introduction) [Batch Scrape](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/scrape \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"url\": \"<string>\",\\n  \"formats\": [\\\\\\n    \"markdown\"\\\\\\n  ],\\n  \"onlyMainContent\": true,\\n  \"includeTags\": [\\\\\\n    \"<string>\"\\\\\\n  ],\\n  \"excludeTags\": [\\\\\\n    \"<string>\"\\\\\\n  ],\\n  \"headers\": {},\\n  \"waitFor\": 0,\\n  \"mobile\": false,\\n  \"skipTlsVerification\": false,\\n  \"timeout\": 30000,\\n  \"jsonOptions\": {\\n    \"schema\": {},\\n    \"systemPrompt\": \"<string>\",\\n    \"prompt\": \"<string>\"\\n  },\\n  \"actions\": [\\\\\\n    {\\\\\\n      \"type\": \"wait\",\\\\\\n      \"milliseconds\": 2,\\\\\\n      \"selector\": \"#my-element\"\\\\\\n    }\\\\\\n  ],\\n  \"location\": {\\n    \"country\": \"US\",\\n    \"languages\": [\\\\\\n      \"en-US\"\\\\\\n    ]\\n  },\\n  \"removeBase64Images\": true,\\n  \"blockAds\": true,\\n  \"proxy\": \"basic\"\\n}\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"data\": {\\n    \"markdown\": \"<string>\",\\n    \"html\": \"<string>\",\\n    \"rawHtml\": \"<string>\",\\n    \"screenshot\": \"<string>\",\\n    \"links\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"actions\": {\\n      \"screenshots\": [\\\\\\n        \"<string>\"\\\\\\n      ]\\n    },\\n    \"metadata\": {\\n      \"title\": \"<string>\",\\n      \"description\": \"<string>\",\\n      \"language\": \"<string>\",\\n      \"sourceURL\": \"<string>\",\\n      \"<any other metadata> \": \"<string>\",\\n      \"statusCode\": 123,\\n      \"error\": \"<string>\"\\n    },\\n    \"llm_extraction\": {},\\n    \"warning\": \"<string>\"\\n  }\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/api-reference/endpoint/scrape',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nScrape Endpoints\\n\\nScrape\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nPOST\\n\\n/\\n\\nscrape\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/scrape \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"url\": \"<string>\",\\n  \"formats\": [\\\\\\n    \"markdown\"\\\\\\n  ],\\n  \"onlyMainContent\": true,\\n  \"includeTags\": [\\\\\\n    \"<string>\"\\\\\\n  ],\\n  \"excludeTags\": [\\\\\\n    \"<string>\"\\\\\\n  ],\\n  \"headers\": {},\\n  \"waitFor\": 0,\\n  \"mobile\": false,\\n  \"skipTlsVerification\": false,\\n  \"timeout\": 30000,\\n  \"jsonOptions\": {\\n    \"schema\": {},\\n    \"systemPrompt\": \"<string>\",\\n    \"prompt\": \"<string>\"\\n  },\\n  \"actions\": [\\\\\\n    {\\\\\\n      \"type\": \"wait\",\\\\\\n      \"milliseconds\": 2,\\\\\\n      \"selector\": \"#my-element\"\\\\\\n    }\\\\\\n  ],\\n  \"location\": {\\n    \"country\": \"US\",\\n    \"languages\": [\\\\\\n      \"en-US\"\\\\\\n    ]\\n  },\\n  \"removeBase64Images\": true,\\n  \"blockAds\": true,\\n  \"proxy\": \"basic\"\\n}\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"data\": {\\n    \"markdown\": \"<string>\",\\n    \"html\": \"<string>\",\\n    \"rawHtml\": \"<string>\",\\n    \"screenshot\": \"<string>\",\\n    \"links\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"actions\": {\\n      \"screenshots\": [\\\\\\n        \"<string>\"\\\\\\n      ]\\n    },\\n    \"metadata\": {\\n      \"title\": \"<string>\",\\n      \"description\": \"<string>\",\\n      \"language\": \"<string>\",\\n      \"sourceURL\": \"<string>\",\\n      \"<any other metadata> \": \"<string>\",\\n      \"statusCode\": 123,\\n      \"error\": \"<string>\"\\n    },\\n    \"llm_extraction\": {},\\n    \"warning\": \"<string>\"\\n  }\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Body\\n\\napplication/json\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-url)\\n\\nurl\\n\\nstring\\n\\nrequired\\n\\nThe URL to scrape\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-formats)\\n\\nformats\\n\\nenum<string>\\\\[\\\\]\\n\\nFormats to include in the output.\\n\\nAvailable options:\\n\\n`markdown`,\\n\\n`html`,\\n\\n`rawHtml`,\\n\\n`links`,\\n\\n`screenshot`,\\n\\n`screenshot@fullPage`,\\n\\n`json`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-only-main-content)\\n\\nonlyMainContent\\n\\nboolean\\n\\ndefault:true\\n\\nOnly return the main content of the page excluding headers, navs, footers, etc.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-include-tags)\\n\\nincludeTags\\n\\nstring\\\\[\\\\]\\n\\nTags to include in the output.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-exclude-tags)\\n\\nexcludeTags\\n\\nstring\\\\[\\\\]\\n\\nTags to exclude from the output.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-headers)\\n\\nheaders\\n\\nobject\\n\\nHeaders to send with the request. Can be used to send cookies, user-agent, etc.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-wait-for)\\n\\nwaitFor\\n\\ninteger\\n\\ndefault:0\\n\\nSpecify a delay in milliseconds before fetching the content, allowing the page sufficient time to load.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-mobile)\\n\\nmobile\\n\\nboolean\\n\\ndefault:false\\n\\nSet to true if you want to emulate scraping from a mobile device. Useful for testing responsive pages and taking mobile screenshots.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-skip-tls-verification)\\n\\nskipTlsVerification\\n\\nboolean\\n\\ndefault:false\\n\\nSkip TLS certificate verification when making requests\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-timeout)\\n\\ntimeout\\n\\ninteger\\n\\ndefault:30000\\n\\nTimeout in milliseconds for the request\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-json-options)\\n\\njsonOptions\\n\\nobject\\n\\nExtract object\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-json-options-schema)\\n\\njsonOptions.schema\\n\\nobject\\n\\nThe schema to use for the extraction (Optional)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-json-options-system-prompt)\\n\\njsonOptions.systemPrompt\\n\\nstring\\n\\nThe system prompt to use for the extraction (Optional)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-json-options-prompt)\\n\\njsonOptions.prompt\\n\\nstring\\n\\nThe prompt to use for the extraction without a schema (Optional)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-actions)\\n\\nactions\\n\\nobject\\\\[\\\\]\\n\\nActions to perform on the page before grabbing the content\\n\\n- Wait\\n- Screenshot\\n- Click\\n- Write text\\n- Press a key\\n- Scroll\\n- Scrape\\n- Execute JavaScript\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-actions-type)\\n\\nactions.type\\n\\nenum<string>\\n\\nrequired\\n\\nWait for a specified amount of milliseconds\\n\\nAvailable options:\\n\\n`wait`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-actions-milliseconds)\\n\\nactions.milliseconds\\n\\ninteger\\n\\nNumber of milliseconds to wait\\n\\nRequired range: `x >= 1`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-actions-selector)\\n\\nactions.selector\\n\\nstring\\n\\nQuery selector to find the element by\\n\\nExample:\\n\\n`\"#my-element\"`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-location)\\n\\nlocation\\n\\nobject\\n\\nLocation settings for the request. When specified, this will use an appropriate proxy if available and emulate the corresponding language and timezone settings. Defaults to \\'US\\' if not specified.\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-location-country)\\n\\nlocation.country\\n\\nstring\\n\\ndefault:US\\n\\nISO 3166-1 alpha-2 country code (e.g., \\'US\\', \\'AU\\', \\'DE\\', \\'JP\\')\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-location-languages)\\n\\nlocation.languages\\n\\nstring\\\\[\\\\]\\n\\nPreferred languages and locales for the request in order of priority. Defaults to the language of the specified location. See [https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Language](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Language)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-remove-base64-images)\\n\\nremoveBase64Images\\n\\nboolean\\n\\nRemoves all base 64 images from the output, which may be overwhelmingly long. The image\\'s alt text remains in the output, but the URL is replaced with a placeholder.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-block-ads)\\n\\nblockAds\\n\\nboolean\\n\\ndefault:true\\n\\nEnables ad-blocking and cookie popup blocking.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#body-proxy)\\n\\nproxy\\n\\nenum<string>\\n\\nSpecifies the type of proxy to use.\\n\\n- **basic**: Proxies for scraping sites with none to basic anti-bot solutions. Fast and usually works.\\n- **stealth**: Stealth proxies for scraping sites with advanced anti-bot solutions. Slower, but more reliable on certain sites.\\n\\nIf you do not specify a proxy, Firecrawl will automatically attempt to determine which one you need based on the target site.\\n\\nAvailable options:\\n\\n`basic`,\\n\\n`stealth`\\n\\n#### Response\\n\\n200\\n\\n200402429500\\n\\napplication/json\\n\\nSuccessful response\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-success)\\n\\nsuccess\\n\\nboolean\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data)\\n\\ndata\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-markdown)\\n\\ndata.markdown\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-html)\\n\\ndata.html\\n\\nstring \\\\| null\\n\\nHTML version of the content on page if `html` is in `formats`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-raw-html)\\n\\ndata.rawHtml\\n\\nstring \\\\| null\\n\\nRaw HTML content of the page if `rawHtml` is in `formats`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-screenshot)\\n\\ndata.screenshot\\n\\nstring \\\\| null\\n\\nScreenshot of the page if `screenshot` is in `formats`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-links)\\n\\ndata.links\\n\\nstring\\\\[\\\\]\\n\\nList of links on the page if `links` is in `formats`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-actions)\\n\\ndata.actions\\n\\nobject \\\\| null\\n\\nResults of the actions specified in the `actions` parameter. Only present if the `actions` parameter was provided in the request\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-actions-screenshots)\\n\\ndata.actions.screenshots\\n\\nstring\\\\[\\\\]\\n\\nScreenshot URLs, in the same order as the screenshot actions provided.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-metadata)\\n\\ndata.metadata\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-metadata-title)\\n\\ndata.metadata.title\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-metadata-description)\\n\\ndata.metadata.description\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-metadata-language)\\n\\ndata.metadata.language\\n\\nstring \\\\| null\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-metadata-source-url)\\n\\ndata.metadata.sourceURL\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-metadata-any-other-metadata)\\n\\ndata.metadata.<any other metadata>\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-metadata-status-code)\\n\\ndata.metadata.statusCode\\n\\ninteger\\n\\nThe status code of the page\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-metadata-error)\\n\\ndata.metadata.error\\n\\nstring \\\\| null\\n\\nThe error message of the page\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-llm-extraction)\\n\\ndata.llm\\\\_extraction\\n\\nobject \\\\| null\\n\\nDisplayed when using LLM Extraction. Extracted data from the page following the schema defined.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/scrape#response-data-warning)\\n\\ndata.warning\\n\\nstring \\\\| null\\n\\nCan be displayed when using LLM Extraction. Warning message will let you know any issues with the extraction.\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/api-reference/endpoint/scrape.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/scrape)\\n\\n[Introduction](https://docs.firecrawl.dev/api-reference/introduction) [Batch Scrape](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/scrape \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"url\": \"<string>\",\\n  \"formats\": [\\\\\\n    \"markdown\"\\\\\\n  ],\\n  \"onlyMainContent\": true,\\n  \"includeTags\": [\\\\\\n    \"<string>\"\\\\\\n  ],\\n  \"excludeTags\": [\\\\\\n    \"<string>\"\\\\\\n  ],\\n  \"headers\": {},\\n  \"waitFor\": 0,\\n  \"mobile\": false,\\n  \"skipTlsVerification\": false,\\n  \"timeout\": 30000,\\n  \"jsonOptions\": {\\n    \"schema\": {},\\n    \"systemPrompt\": \"<string>\",\\n    \"prompt\": \"<string>\"\\n  },\\n  \"actions\": [\\\\\\n    {\\\\\\n      \"type\": \"wait\",\\\\\\n      \"milliseconds\": 2,\\\\\\n      \"selector\": \"#my-element\"\\\\\\n    }\\\\\\n  ],\\n  \"location\": {\\n    \"country\": \"US\",\\n    \"languages\": [\\\\\\n      \"en-US\"\\\\\\n    ]\\n  },\\n  \"removeBase64Images\": true,\\n  \"blockAds\": true,\\n  \"proxy\": \"basic\"\\n}\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"data\": {\\n    \"markdown\": \"<string>\",\\n    \"html\": \"<string>\",\\n    \"rawHtml\": \"<string>\",\\n    \"screenshot\": \"<string>\",\\n    \"links\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"actions\": {\\n      \"screenshots\": [\\\\\\n        \"<string>\"\\\\\\n      ]\\n    },\\n    \"metadata\": {\\n      \"title\": \"<string>\",\\n      \"description\": \"<string>\",\\n      \"language\": \"<string>\",\\n      \"sourceURL\": \"<string>\",\\n      \"<any other metadata> \": \"<string>\",\\n      \"statusCode\": 123,\\n      \"error\": \"<string>\"\\n    },\\n    \"llm_extraction\": {},\\n    \"warning\": \"<string>\"\\n  }\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/api-reference/endpoint/crawl-get',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nCrawl Endpoints\\n\\nGet Crawl Status\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nGET\\n\\n/\\n\\ncrawl\\n\\n/\\n\\n{id}\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request GET \\\\\\n  --url https://api.firecrawl.dev/v1/crawl/{id} \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"status\": \"<string>\",\\n  \"total\": 123,\\n  \"completed\": 123,\\n  \"creditsUsed\": 123,\\n  \"expiresAt\": \"2023-11-07T05:31:56Z\",\\n  \"next\": \"<string>\",\\n  \"data\": [\\\\\\n    {\\\\\\n      \"markdown\": \"<string>\",\\\\\\n      \"html\": \"<string>\",\\\\\\n      \"rawHtml\": \"<string>\",\\\\\\n      \"links\": [\\\\\\n        \"<string>\"\\\\\\n      ],\\\\\\n      \"screenshot\": \"<string>\",\\\\\\n      \"metadata\": {\\\\\\n        \"title\": \"<string>\",\\\\\\n        \"description\": \"<string>\",\\\\\\n        \"language\": \"<string>\",\\\\\\n        \"sourceURL\": \"<string>\",\\\\\\n        \"<any other metadata> \": \"<string>\",\\\\\\n        \"statusCode\": 123,\\\\\\n        \"error\": \"<string>\"\\\\\\n      }\\\\\\n    }\\\\\\n  ]\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Path Parameters\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#parameter-id)\\n\\nid\\n\\nstring\\n\\nrequired\\n\\nThe ID of the crawl job\\n\\n#### Response\\n\\n200\\n\\n200402429500\\n\\napplication/json\\n\\nSuccessful response\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#response-status)\\n\\nstatus\\n\\nstring\\n\\nThe current status of the crawl. Can be `scraping`, `completed`, or `failed`.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#response-total)\\n\\ntotal\\n\\ninteger\\n\\nThe total number of pages that were attempted to be crawled.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#response-completed)\\n\\ncompleted\\n\\ninteger\\n\\nThe number of pages that have been successfully crawled.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#response-credits-used)\\n\\ncreditsUsed\\n\\ninteger\\n\\nThe number of credits used for the crawl.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#response-expires-at)\\n\\nexpiresAt\\n\\nstring\\n\\nThe date and time when the crawl will expire.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#response-next)\\n\\nnext\\n\\nstring \\\\| null\\n\\nThe URL to retrieve the next 10MB of data. Returned if the crawl is not completed or if the response is larger than 10MB.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#response-data)\\n\\ndata\\n\\nobject\\\\[\\\\]\\n\\nThe data of the crawl.\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#response-data-markdown)\\n\\ndata.markdown\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#response-data-html)\\n\\ndata.html\\n\\nstring \\\\| null\\n\\nHTML version of the content on page if `includeHtml` is true\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#response-data-raw-html)\\n\\ndata.rawHtml\\n\\nstring \\\\| null\\n\\nRaw HTML content of the page if `includeRawHtml` is true\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#response-data-links)\\n\\ndata.links\\n\\nstring\\\\[\\\\]\\n\\nList of links on the page if `includeLinks` is true\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#response-data-screenshot)\\n\\ndata.screenshot\\n\\nstring \\\\| null\\n\\nScreenshot of the page if `includeScreenshot` is true\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#response-data-metadata)\\n\\ndata.metadata\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#response-data-metadata-title)\\n\\ndata.metadata.title\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#response-data-metadata-description)\\n\\ndata.metadata.description\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#response-data-metadata-language)\\n\\ndata.metadata.language\\n\\nstring \\\\| null\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#response-data-metadata-source-url)\\n\\ndata.metadata.sourceURL\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#response-data-metadata-any-other-metadata)\\n\\ndata.metadata.<any other metadata>\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#response-data-metadata-status-code)\\n\\ndata.metadata.statusCode\\n\\ninteger\\n\\nThe status code of the page\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#response-data-metadata-error)\\n\\ndata.metadata.error\\n\\nstring \\\\| null\\n\\nThe error message of the page\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/api-reference/endpoint/crawl-get.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/crawl-get)\\n\\n[Crawl](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post) [Cancel Crawl](https://docs.firecrawl.dev/api-reference/endpoint/crawl-delete)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request GET \\\\\\n  --url https://api.firecrawl.dev/v1/crawl/{id} \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"status\": \"<string>\",\\n  \"total\": 123,\\n  \"completed\": 123,\\n  \"creditsUsed\": 123,\\n  \"expiresAt\": \"2023-11-07T05:31:56Z\",\\n  \"next\": \"<string>\",\\n  \"data\": [\\\\\\n    {\\\\\\n      \"markdown\": \"<string>\",\\\\\\n      \"html\": \"<string>\",\\\\\\n      \"rawHtml\": \"<string>\",\\\\\\n      \"links\": [\\\\\\n        \"<string>\"\\\\\\n      ],\\\\\\n      \"screenshot\": \"<string>\",\\\\\\n      \"metadata\": {\\\\\\n        \"title\": \"<string>\",\\\\\\n        \"description\": \"<string>\",\\\\\\n        \"language\": \"<string>\",\\\\\\n        \"sourceURL\": \"<string>\",\\\\\\n        \"<any other metadata> \": \"<string>\",\\\\\\n        \"statusCode\": 123,\\\\\\n        \"error\": \"<string>\"\\\\\\n      }\\\\\\n    }\\\\\\n  ]\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nScrape Endpoints\\n\\nGet Batch Scrape Status\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nGET\\n\\n/\\n\\nbatch\\n\\n/\\n\\nscrape\\n\\n/\\n\\n{id}\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request GET \\\\\\n  --url https://api.firecrawl.dev/v1/batch/scrape/{id} \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"status\": \"<string>\",\\n  \"total\": 123,\\n  \"completed\": 123,\\n  \"creditsUsed\": 123,\\n  \"expiresAt\": \"2023-11-07T05:31:56Z\",\\n  \"next\": \"<string>\",\\n  \"data\": [\\\\\\n    {\\\\\\n      \"markdown\": \"<string>\",\\\\\\n      \"html\": \"<string>\",\\\\\\n      \"rawHtml\": \"<string>\",\\\\\\n      \"links\": [\\\\\\n        \"<string>\"\\\\\\n      ],\\\\\\n      \"screenshot\": \"<string>\",\\\\\\n      \"metadata\": {\\\\\\n        \"title\": \"<string>\",\\\\\\n        \"description\": \"<string>\",\\\\\\n        \"language\": \"<string>\",\\\\\\n        \"sourceURL\": \"<string>\",\\\\\\n        \"<any other metadata> \": \"<string>\",\\\\\\n        \"statusCode\": 123,\\\\\\n        \"error\": \"<string>\"\\\\\\n      }\\\\\\n    }\\\\\\n  ]\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Path Parameters\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#parameter-id)\\n\\nid\\n\\nstring\\n\\nrequired\\n\\nThe ID of the batch scrape job\\n\\n#### Response\\n\\n200\\n\\n200402429500\\n\\napplication/json\\n\\nSuccessful response\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-status)\\n\\nstatus\\n\\nstring\\n\\nThe current status of the batch scrape. Can be `scraping`, `completed`, or `failed`.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-total)\\n\\ntotal\\n\\ninteger\\n\\nThe total number of pages that were attempted to be scraped.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-completed)\\n\\ncompleted\\n\\ninteger\\n\\nThe number of pages that have been successfully scraped.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-credits-used)\\n\\ncreditsUsed\\n\\ninteger\\n\\nThe number of credits used for the batch scrape.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-expires-at)\\n\\nexpiresAt\\n\\nstring\\n\\nThe date and time when the batch scrape will expire.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-next)\\n\\nnext\\n\\nstring \\\\| null\\n\\nThe URL to retrieve the next 10MB of data. Returned if the batch scrape is not completed or if the response is larger than 10MB.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-data)\\n\\ndata\\n\\nobject\\\\[\\\\]\\n\\nThe data of the batch scrape.\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-data-markdown)\\n\\ndata.markdown\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-data-html)\\n\\ndata.html\\n\\nstring \\\\| null\\n\\nHTML version of the content on page if `includeHtml` is true\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-data-raw-html)\\n\\ndata.rawHtml\\n\\nstring \\\\| null\\n\\nRaw HTML content of the page if `includeRawHtml` is true\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-data-links)\\n\\ndata.links\\n\\nstring\\\\[\\\\]\\n\\nList of links on the page if `includeLinks` is true\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-data-screenshot)\\n\\ndata.screenshot\\n\\nstring \\\\| null\\n\\nScreenshot of the page if `includeScreenshot` is true\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-data-metadata)\\n\\ndata.metadata\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-data-metadata-title)\\n\\ndata.metadata.title\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-data-metadata-description)\\n\\ndata.metadata.description\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-data-metadata-language)\\n\\ndata.metadata.language\\n\\nstring \\\\| null\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-data-metadata-source-url)\\n\\ndata.metadata.sourceURL\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-data-metadata-any-other-metadata)\\n\\ndata.metadata.<any other metadata>\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-data-metadata-status-code)\\n\\ndata.metadata.statusCode\\n\\ninteger\\n\\nThe status code of the page\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-data-metadata-error)\\n\\ndata.metadata.error\\n\\nstring \\\\| null\\n\\nThe error message of the page\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/api-reference/endpoint/batch-scrape-get.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/batch-scrape-get)\\n\\n[Batch Scrape](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape) [Get Batch Scrape Errors](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get-errors)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request GET \\\\\\n  --url https://api.firecrawl.dev/v1/batch/scrape/{id} \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"status\": \"<string>\",\\n  \"total\": 123,\\n  \"completed\": 123,\\n  \"creditsUsed\": 123,\\n  \"expiresAt\": \"2023-11-07T05:31:56Z\",\\n  \"next\": \"<string>\",\\n  \"data\": [\\\\\\n    {\\\\\\n      \"markdown\": \"<string>\",\\\\\\n      \"html\": \"<string>\",\\\\\\n      \"rawHtml\": \"<string>\",\\\\\\n      \"links\": [\\\\\\n        \"<string>\"\\\\\\n      ],\\\\\\n      \"screenshot\": \"<string>\",\\\\\\n      \"metadata\": {\\\\\\n        \"title\": \"<string>\",\\\\\\n        \"description\": \"<string>\",\\\\\\n        \"language\": \"<string>\",\\\\\\n        \"sourceURL\": \"<string>\",\\\\\\n        \"<any other metadata> \": \"<string>\",\\\\\\n        \"statusCode\": 123,\\\\\\n        \"error\": \"<string>\"\\\\\\n      }\\\\\\n    }\\\\\\n  ]\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nScrape\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nPOST\\n\\n/\\n\\nscrape\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v0/scrape \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"url\": \"<string>\",\\n  \"pageOptions\": {\\n    \"headers\": {},\\n    \"includeHtml\": false,\\n    \"includeRawHtml\": false,\\n    \"onlyIncludeTags\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"onlyMainContent\": false,\\n    \"removeTags\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"replaceAllPathsWithAbsolutePaths\": false,\\n    \"screenshot\": false,\\n    \"fullPageScreenshot\": false,\\n    \"waitFor\": 0\\n  },\\n  \"extractorOptions\": {},\\n  \"timeout\": 30000\\n}\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"data\": {\\n    \"markdown\": \"<string>\",\\n    \"content\": \"<string>\",\\n    \"html\": \"<string>\",\\n    \"rawHtml\": \"<string>\",\\n    \"metadata\": {\\n      \"title\": \"<string>\",\\n      \"description\": \"<string>\",\\n      \"language\": \"<string>\",\\n      \"sourceURL\": \"<string>\",\\n      \"<any other metadata> \": \"<string>\",\\n      \"pageStatusCode\": 123,\\n      \"pageError\": \"<string>\"\\n    },\\n    \"llm_extraction\": {},\\n    \"warning\": \"<string>\"\\n  }\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Body\\n\\napplication/json\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#body-url)\\n\\nurl\\n\\nstring\\n\\nrequired\\n\\nThe URL to scrape\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#body-page-options)\\n\\npageOptions\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#body-page-options-headers)\\n\\npageOptions.headers\\n\\nobject\\n\\nHeaders to send with the request. Can be used to send cookies, user-agent, etc.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#body-page-options-include-html)\\n\\npageOptions.includeHtml\\n\\nboolean\\n\\ndefault:false\\n\\nInclude the HTML version of the content on page. Will output a html key in the response.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#body-page-options-include-raw-html)\\n\\npageOptions.includeRawHtml\\n\\nboolean\\n\\ndefault:false\\n\\nInclude the raw HTML content of the page. Will output a rawHtml key in the response.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#body-page-options-only-include-tags)\\n\\npageOptions.onlyIncludeTags\\n\\nstring\\\\[\\\\]\\n\\nOnly include tags, classes and ids from the page in the final output. Use comma separated values. Example: \\'script, .ad, #footer\\'\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#body-page-options-only-main-content)\\n\\npageOptions.onlyMainContent\\n\\nboolean\\n\\ndefault:false\\n\\nOnly return the main content of the page excluding headers, navs, footers, etc.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#body-page-options-remove-tags)\\n\\npageOptions.removeTags\\n\\nstring\\\\[\\\\]\\n\\nTags, classes and ids to remove from the page. Use comma separated values. Example: \\'script, .ad, #footer\\'\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#body-page-options-replace-all-paths-with-absolute-paths)\\n\\npageOptions.replaceAllPathsWithAbsolutePaths\\n\\nboolean\\n\\ndefault:false\\n\\nReplace all relative paths with absolute paths for images and links\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#body-page-options-screenshot)\\n\\npageOptions.screenshot\\n\\nboolean\\n\\ndefault:false\\n\\nInclude a screenshot of the top of the page that you are scraping.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#body-page-options-full-page-screenshot)\\n\\npageOptions.fullPageScreenshot\\n\\nboolean\\n\\ndefault:false\\n\\nInclude a full page screenshot of the page that you are scraping.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#body-page-options-wait-for)\\n\\npageOptions.waitFor\\n\\ninteger\\n\\ndefault:0\\n\\nWait x amount of milliseconds for the page to load to fetch content\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#body-extractor-options)\\n\\nextractorOptions\\n\\nobject\\n\\nOptions for extraction of structured information from the page content. Note: LLM-based extraction is not performed by default and only occurs when explicitly configured. The \\'markdown\\' mode simply returns the scraped markdown and is the default mode for scraping.\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#body-extractor-options-mode)\\n\\nextractorOptions.mode\\n\\nenum<string>\\n\\nThe extraction mode to use. \\'markdown\\': Returns the scraped markdown content, does not perform LLM extraction. \\'llm-extraction\\': Extracts information from the cleaned and parsed content using LLM. \\'llm-extraction-from-raw-html\\': Extracts information directly from the raw HTML using LLM. \\'llm-extraction-from-markdown\\': Extracts information from the markdown content using LLM.\\n\\nAvailable options:\\n\\n`markdown`,\\n\\n`llm-extraction`,\\n\\n`llm-extraction-from-raw-html`,\\n\\n`llm-extraction-from-markdown`\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#body-extractor-options-extraction-prompt)\\n\\nextractorOptions.extractionPrompt\\n\\nstring\\n\\nA prompt describing what information to extract from the page, applicable for LLM extraction modes.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#body-extractor-options-extraction-schema)\\n\\nextractorOptions.extractionSchema\\n\\nobject\\n\\nThe schema for the data to be extracted, required only for LLM extraction modes.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#body-timeout)\\n\\ntimeout\\n\\ninteger\\n\\ndefault:30000\\n\\nTimeout in milliseconds for the request\\n\\n#### Response\\n\\n200\\n\\n200402429500\\n\\napplication/json\\n\\nSuccessful response\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#response-success)\\n\\nsuccess\\n\\nboolean\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#response-data)\\n\\ndata\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#response-data-markdown)\\n\\ndata.markdown\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#response-data-content)\\n\\ndata.content\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#response-data-html)\\n\\ndata.html\\n\\nstring \\\\| null\\n\\nHTML version of the content on page if `includeHtml` is true\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#response-data-raw-html)\\n\\ndata.rawHtml\\n\\nstring \\\\| null\\n\\nRaw HTML content of the page if `includeRawHtml` is true\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#response-data-metadata)\\n\\ndata.metadata\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#response-data-metadata-title)\\n\\ndata.metadata.title\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#response-data-metadata-description)\\n\\ndata.metadata.description\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#response-data-metadata-language)\\n\\ndata.metadata.language\\n\\nstring \\\\| null\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#response-data-metadata-source-url)\\n\\ndata.metadata.sourceURL\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#response-data-metadata-any-other-metadata)\\n\\ndata.metadata.<any other metadata>\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#response-data-metadata-page-status-code)\\n\\ndata.metadata.pageStatusCode\\n\\ninteger\\n\\nThe status code of the page\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#response-data-metadata-page-error)\\n\\ndata.metadata.pageError\\n\\nstring \\\\| null\\n\\nThe error message of the page\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#response-data-llm-extraction)\\n\\ndata.llm\\\\_extraction\\n\\nobject \\\\| null\\n\\nDisplayed when using LLM Extraction. Extracted data from the page following the schema defined.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/scrape#response-data-warning)\\n\\ndata.warning\\n\\nstring \\\\| null\\n\\nCan be displayed when using LLM Extraction. Warning message will let you know any issues with the extraction.\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/v0/api-reference/endpoint/scrape.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/v0/api-reference/endpoint/scrape)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v0/scrape \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"url\": \"<string>\",\\n  \"pageOptions\": {\\n    \"headers\": {},\\n    \"includeHtml\": false,\\n    \"includeRawHtml\": false,\\n    \"onlyIncludeTags\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"onlyMainContent\": false,\\n    \"removeTags\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"replaceAllPathsWithAbsolutePaths\": false,\\n    \"screenshot\": false,\\n    \"fullPageScreenshot\": false,\\n    \"waitFor\": 0\\n  },\\n  \"extractorOptions\": {},\\n  \"timeout\": 30000\\n}\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"data\": {\\n    \"markdown\": \"<string>\",\\n    \"content\": \"<string>\",\\n    \"html\": \"<string>\",\\n    \"rawHtml\": \"<string>\",\\n    \"metadata\": {\\n      \"title\": \"<string>\",\\n      \"description\": \"<string>\",\\n      \"language\": \"<string>\",\\n      \"sourceURL\": \"<string>\",\\n      \"<any other metadata> \": \"<string>\",\\n      \"pageStatusCode\": 123,\\n      \"pageError\": \"<string>\"\\n    },\\n    \"llm_extraction\": {},\\n    \"warning\": \"<string>\"\\n  }\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/api-reference/endpoint/crawl-delete',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nCrawl Endpoints\\n\\nCancel Crawl\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nDELETE\\n\\n/\\n\\ncrawl\\n\\n/\\n\\n{id}\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request DELETE \\\\\\n  --url https://api.firecrawl.dev/v1/crawl/{id} \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\n404\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"status\": \"cancelled\"\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-delete#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Path Parameters\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-delete#parameter-id)\\n\\nid\\n\\nstring\\n\\nrequired\\n\\nThe ID of the crawl job\\n\\n#### Response\\n\\n200\\n\\n200404500\\n\\napplication/json\\n\\nSuccessful cancellation\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/crawl-delete#response-status)\\n\\nstatus\\n\\nenum<string>\\n\\nAvailable options:\\n\\n`cancelled`\\n\\nExample:\\n\\n`\"cancelled\"`\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/api-reference/endpoint/crawl-delete.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/crawl-delete)\\n\\n[Get Crawl Status](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get) [Get Crawl Errors](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get-errors)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request DELETE \\\\\\n  --url https://api.firecrawl.dev/v1/crawl/{id} \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\n404\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"status\": \"cancelled\"\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/v0/api-reference/endpoint/status',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nGet Crawl Status\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nGET\\n\\n/\\n\\ncrawl\\n\\n/\\n\\nstatus\\n\\n/\\n\\n{jobId}\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request GET \\\\\\n  --url https://api.firecrawl.dev/v0/crawl/status/{jobId} \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"status\": \"<string>\",\\n  \"current\": 123,\\n  \"total\": 123,\\n  \"data\": [\\\\\\n    {\\\\\\n      \"markdown\": \"<string>\",\\\\\\n      \"content\": \"<string>\",\\\\\\n      \"html\": \"<string>\",\\\\\\n      \"rawHtml\": \"<string>\",\\\\\\n      \"index\": 123,\\\\\\n      \"metadata\": {\\\\\\n        \"title\": \"<string>\",\\\\\\n        \"description\": \"<string>\",\\\\\\n        \"language\": \"<string>\",\\\\\\n        \"sourceURL\": \"<string>\",\\\\\\n        \"<any other metadata> \": \"<string>\",\\\\\\n        \"pageStatusCode\": 123,\\\\\\n        \"pageError\": \"<string>\"\\\\\\n      }\\\\\\n    }\\\\\\n  ],\\n  \"partial_data\": [\\\\\\n    {\\\\\\n      \"markdown\": \"<string>\",\\\\\\n      \"content\": \"<string>\",\\\\\\n      \"html\": \"<string>\",\\\\\\n      \"rawHtml\": \"<string>\",\\\\\\n      \"index\": 123,\\\\\\n      \"metadata\": {\\\\\\n        \"title\": \"<string>\",\\\\\\n        \"description\": \"<string>\",\\\\\\n        \"language\": \"<string>\",\\\\\\n        \"sourceURL\": \"<string>\",\\\\\\n        \"<any other metadata> \": \"<string>\",\\\\\\n        \"pageStatusCode\": 123,\\\\\\n        \"pageError\": \"<string>\"\\\\\\n      }\\\\\\n    }\\\\\\n  ]\\n}\\n```\\n\\nThis endpoint retrieves the status of a crawl job. If the job is not completed, the response includes content within `partial_data`. Once the job is completed, the content is available under `data`.\\n\\n**We recommend keeping track of the crawl jobs yourself as the crawl status results can expire after 24 hours.**\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Path Parameters\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#parameter-job-id)\\n\\njobId\\n\\nstring\\n\\nrequired\\n\\nID of the crawl job\\n\\n#### Response\\n\\n200\\n\\n200402429500\\n\\napplication/json\\n\\nSuccessful response\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-status)\\n\\nstatus\\n\\nstring\\n\\nStatus of the job (completed, active, failed, paused)\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-current)\\n\\ncurrent\\n\\ninteger\\n\\nCurrent page number\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-total)\\n\\ntotal\\n\\ninteger\\n\\nTotal number of pages\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-data)\\n\\ndata\\n\\nobject\\\\[\\\\]\\n\\nData returned from the job (null when it is in progress)\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-data-markdown)\\n\\ndata.markdown\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-data-content)\\n\\ndata.content\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-data-html)\\n\\ndata.html\\n\\nstring \\\\| null\\n\\nHTML version of the content on page if `includeHtml` is true\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-data-raw-html)\\n\\ndata.rawHtml\\n\\nstring \\\\| null\\n\\nRaw HTML content of the page if `includeRawHtml` is true\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-data-index)\\n\\ndata.index\\n\\ninteger\\n\\nThe number of the page that was crawled. This is useful for `partial_data` so you know which page the data is from.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-data-metadata)\\n\\ndata.metadata\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-data-metadata-title)\\n\\ndata.metadata.title\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-data-metadata-description)\\n\\ndata.metadata.description\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-data-metadata-language)\\n\\ndata.metadata.language\\n\\nstring \\\\| null\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-data-metadata-source-url)\\n\\ndata.metadata.sourceURL\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-data-metadata-any-other-metadata)\\n\\ndata.metadata.<any other metadata>\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-data-metadata-page-status-code)\\n\\ndata.metadata.pageStatusCode\\n\\ninteger\\n\\nThe status code of the page\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-data-metadata-page-error)\\n\\ndata.metadata.pageError\\n\\nstring \\\\| null\\n\\nThe error message of the page\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-partial-data)\\n\\npartial\\\\_data\\n\\nobject\\\\[\\\\]\\n\\nPartial documents returned as it is being crawled (streaming). **This feature is currently in alpha - expect breaking changes** When a page is ready, it will append to the partial\\\\_data array, so there is no need to wait for the entire website to be crawled. When the crawl is done, partial\\\\_data will become empty and the result will be available in `data`. There is a max of 50 items in the array response. The oldest item (top of the array) will be removed when the new item is added to the array.\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-partial-data-markdown)\\n\\npartial\\\\_data.markdown\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-partial-data-content)\\n\\npartial\\\\_data.content\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-partial-data-html)\\n\\npartial\\\\_data.html\\n\\nstring \\\\| null\\n\\nHTML version of the content on page if `includeHtml` is true\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-partial-data-raw-html)\\n\\npartial\\\\_data.rawHtml\\n\\nstring \\\\| null\\n\\nRaw HTML content of the page if `includeRawHtml` is true\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-partial-data-index)\\n\\npartial\\\\_data.index\\n\\ninteger\\n\\nThe number of the page that was crawled. This is useful for `partial_data` so you know which page the data is from.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-partial-data-metadata)\\n\\npartial\\\\_data.metadata\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-partial-data-metadata-title)\\n\\npartial\\\\_data.metadata.title\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-partial-data-metadata-description)\\n\\npartial\\\\_data.metadata.description\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-partial-data-metadata-language)\\n\\npartial\\\\_data.metadata.language\\n\\nstring \\\\| null\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-partial-data-metadata-source-url)\\n\\npartial\\\\_data.metadata.sourceURL\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-partial-data-metadata-any-other-metadata)\\n\\npartial\\\\_data.metadata.<any other metadata>\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-partial-data-metadata-page-status-code)\\n\\npartial\\\\_data.metadata.pageStatusCode\\n\\ninteger\\n\\nThe status code of the page\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/status#response-partial-data-metadata-page-error)\\n\\npartial\\\\_data.metadata.pageError\\n\\nstring \\\\| null\\n\\nThe error message of the page\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/v0/api-reference/endpoint/status.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/v0/api-reference/endpoint/status)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request GET \\\\\\n  --url https://api.firecrawl.dev/v0/crawl/status/{jobId} \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"status\": \"<string>\",\\n  \"current\": 123,\\n  \"total\": 123,\\n  \"data\": [\\\\\\n    {\\\\\\n      \"markdown\": \"<string>\",\\\\\\n      \"content\": \"<string>\",\\\\\\n      \"html\": \"<string>\",\\\\\\n      \"rawHtml\": \"<string>\",\\\\\\n      \"index\": 123,\\\\\\n      \"metadata\": {\\\\\\n        \"title\": \"<string>\",\\\\\\n        \"description\": \"<string>\",\\\\\\n        \"language\": \"<string>\",\\\\\\n        \"sourceURL\": \"<string>\",\\\\\\n        \"<any other metadata> \": \"<string>\",\\\\\\n        \"pageStatusCode\": 123,\\\\\\n        \"pageError\": \"<string>\"\\\\\\n      }\\\\\\n    }\\\\\\n  ],\\n  \"partial_data\": [\\\\\\n    {\\\\\\n      \"markdown\": \"<string>\",\\\\\\n      \"content\": \"<string>\",\\\\\\n      \"html\": \"<string>\",\\\\\\n      \"rawHtml\": \"<string>\",\\\\\\n      \"index\": 123,\\\\\\n      \"metadata\": {\\\\\\n        \"title\": \"<string>\",\\\\\\n        \"description\": \"<string>\",\\\\\\n        \"language\": \"<string>\",\\\\\\n        \"sourceURL\": \"<string>\",\\\\\\n        \"<any other metadata> \": \"<string>\",\\\\\\n        \"pageStatusCode\": 123,\\\\\\n        \"pageError\": \"<string>\"\\\\\\n      }\\\\\\n    }\\\\\\n  ]\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/api-reference/endpoint/deep-research',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nDeep Research\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nPOST\\n\\n/\\n\\ndeep-research\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/deep-research \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"query\": \"<string>\",\\n  \"maxDepth\": 7,\\n  \"timeLimit\": 300,\\n  \"maxUrls\": 20\\n}\\'\\n```\\n\\n200\\n\\n400\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"id\": \"3c90c3cc-0d44-4b50-8888-8dd25736052a\"\\n}\\n```\\n\\nThe Deep Research endpoint enables AI-powered deep research and analysis on any topic. Simply provide a research query, and Firecrawl will autonomously explore the web, gather relevant information, and synthesize findings into comprehensive insights.\\n\\nLooking for the status endpoint? Check out the [Deep Research Status](https://docs.firecrawl.dev/api-reference/endpoint/deep-research-get) endpoint.\\n\\n### [\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research\\\\#response-structure)  Response Structure\\n\\nThe response includes:\\n\\n- **activities**: List of research activities with:\\n  - `type`: Activity type (â€˜searchâ€™, â€˜extractâ€™, â€˜analyzeâ€™, â€˜reasoningâ€™, â€˜synthesisâ€™, â€˜thoughtâ€™)\\n  - `status`: Status (â€˜processingâ€™, â€˜completeâ€™, â€˜errorâ€™)\\n  - `message`: Description of activity/finding\\n  - `timestamp`: ISO timestamp\\n  - `depth`: Research depth level\\n- **sources**: Referenced URLs with:\\n  - `title`: Source title\\n  - `description`: Source description\\n  - `url`: Source URL\\n  - `icon`: Source favicon\\n- **finalAnalysis**: Comprehensive analysis (when completed)\\n\\n- **status**: Overall status (â€˜processingâ€™, â€˜completedâ€™, â€˜failedâ€™)\\n\\n- **currentDepth**: Current research depth\\n\\n- **maxDepth**: Maximum research depth\\n\\n- **totalUrls**: Number of URLs analyzed\\n\\n- **expiresAt**: ISO timestamp when results expire\\n\\n\\n### [\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research\\\\#limitations)  Limitations\\n\\n1. Best suited for topics with publicly available information\\n2. Research jobs limited to 10 minutes maximum\\n3. Manual verification recommended for critical information\\n4. Alpha feature - methodology and output may evolve\\n\\n### [\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research\\\\#billing)  Billing\\n\\nBilling is based on number of URLs analyzed:\\n\\n- Each URL = 1 credit\\n- Control usage with `maxUrls` parameter\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Body\\n\\napplication/json\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research#body-query)\\n\\nquery\\n\\nstring\\n\\nrequired\\n\\nThe query to research\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research#body-max-depth)\\n\\nmaxDepth\\n\\ninteger\\n\\ndefault:7\\n\\nMaximum depth of research iterations\\n\\nRequired range: `1 <= x <= 12`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research#body-time-limit)\\n\\ntimeLimit\\n\\ninteger\\n\\ndefault:300\\n\\nTime limit in seconds\\n\\nRequired range: `30 <= x <= 600`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research#body-max-urls)\\n\\nmaxUrls\\n\\ninteger\\n\\ndefault:20\\n\\nMaximum number of URLs to analyze\\n\\nRequired range: `1 <= x <= 1000`\\n\\n#### Response\\n\\n200\\n\\n200400\\n\\napplication/json\\n\\nResearch job started successfully\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research#response-success)\\n\\nsuccess\\n\\nboolean\\n\\nExample:\\n\\n`true`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/deep-research#response-id)\\n\\nid\\n\\nstring\\n\\nID of the research job\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/api-reference/endpoint/deep-research.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/deep-research)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/deep-research \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"query\": \"<string>\",\\n  \"maxDepth\": 7,\\n  \"timeLimit\": 300,\\n  \"maxUrls\": 20\\n}\\'\\n```\\n\\n200\\n\\n400\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"id\": \"3c90c3cc-0d44-4b50-8888-8dd25736052a\"\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/api-reference/endpoint/llmstxt',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nGenerate LLMs.txt\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nPOST\\n\\n/\\n\\nllmstxt\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/llmstxt \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"url\": \"<string>\",\\n  \"maxUrls\": 2,\\n  \"showFullText\": false\\n}\\'\\n```\\n\\n200\\n\\n400\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"id\": \"3c90c3cc-0d44-4b50-8888-8dd25736052a\"\\n}\\n```\\n\\nThe LLMs.txt generation endpoint creates LLMs.txt and LLMs-full.txt files for any website. These files provide a structured, LLM-friendly format of the websiteâ€™s content, making it easier for language models to understand and process the information.\\n\\nLooking for the status endpoint? Check out the [LLMs.txt Status](https://docs.firecrawl.dev/api-reference/endpoint/llmstxt-get) endpoint.\\n\\n### [\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/llmstxt\\\\#response-structure)  Response Structure\\n\\nThe response includes:\\n\\n- **success**: Boolean indicating if the request was successful\\n- **id**: Unique identifier for the generation job\\n\\n### [\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/llmstxt\\\\#output-format)  Output Format\\n\\n1. **LLMs.txt**\\n   - Concise, structured summary of the website\\n\\n   - Contains key links and descriptions\\n\\n   - Formatted in markdown for easy parsing\\n\\n   - Example:\\n\\n\\n\\n\\n\\n     Copy\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n     ```markdown\\n     # http://example.com llms.txt\\n\\n- [Page Title](https://example.com/page): Brief description\\n- [Another Page](https://example.com/another): Another description\\n\\n```\\n2. **LLMs-full.txt** (when showFullText is true)\\n   - Contains full content of processed pages\\n\\n   - Maintains hierarchical structure\\n\\n   - Includes more detailed information\\n\\n   - Example:\\n\\n\\n\\n\\n\\n     Copy\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n     ```markdown\\n     # http://example.com llms-full.txt\\n\\n     ## Page Title\\n\\n     Full content of the page...\\n\\n     ## Another Page\\n\\n     More detailed content...\\n\\n     ```\\n\\n### [\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/llmstxt\\\\#billing)  Billing\\n\\nBilling is based on API calls and URLs processed:\\n\\n- Base cost: 1 credit per API call\\n- Additional: 1 credit per URL processed\\n- Control URL costs with `maxUrls` parameter\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/llmstxt#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Body\\n\\napplication/json\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/llmstxt#body-url)\\n\\nurl\\n\\nstring\\n\\nrequired\\n\\nThe URL to generate LLMs.txt from\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/llmstxt#body-max-urls)\\n\\nmaxUrls\\n\\ninteger\\n\\ndefault:2\\n\\nMaximum number of URLs to analyze\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/llmstxt#body-show-full-text)\\n\\nshowFullText\\n\\nboolean\\n\\ndefault:false\\n\\nInclude full text content in the response\\n\\n#### Response\\n\\n200\\n\\n200400\\n\\napplication/json\\n\\nLLMs.txt generation job started successfully\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/llmstxt#response-success)\\n\\nsuccess\\n\\nboolean\\n\\nExample:\\n\\n`true`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/llmstxt#response-id)\\n\\nid\\n\\nstring\\n\\nID of the LLMs.txt generation job\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/api-reference/endpoint/llmstxt.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/llmstxt)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/llmstxt \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n\"url\": \"<string>\",\\n\"maxUrls\": 2,\\n\"showFullText\": false\\n}\\'\\n```\\n\\n200\\n\\n400\\n\\nCopy\\n\\n```\\n{\\n\"success\": true,\\n\"id\": \"3c90c3cc-0d44-4b50-8888-8dd25736052a\"\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/api-reference/endpoint/extract',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nExtract Endpoints\\n\\nExtract\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nPOST\\n\\n/\\n\\nextract\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/extract \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"urls\": [\\\\\\n    \"<string>\"\\\\\\n  ],\\n  \"prompt\": \"<string>\",\\n  \"schema\": {\\n    \"property1\": \"<string>\",\\n    \"property2\": 123\\n  },\\n  \"enableWebSearch\": false,\\n  \"ignoreSitemap\": false,\\n  \"includeSubdomains\": true,\\n  \"showSources\": false,\\n  \"scrapeOptions\": {\\n    \"formats\": [\\\\\\n      \"markdown\"\\\\\\n    ],\\n    \"onlyMainContent\": true,\\n    \"includeTags\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"excludeTags\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"headers\": {},\\n    \"waitFor\": 0,\\n    \"mobile\": false,\\n    \"skipTlsVerification\": false,\\n    \"timeout\": 30000,\\n    \"jsonOptions\": {\\n      \"schema\": {},\\n      \"systemPrompt\": \"<string>\",\\n      \"prompt\": \"<string>\"\\n    },\\n    \"actions\": [\\\\\\n      {\\\\\\n        \"type\": \"wait\",\\\\\\n        \"milliseconds\": 2,\\\\\\n        \"selector\": \"#my-element\"\\\\\\n      }\\\\\\n    ],\\n    \"location\": {\\n      \"country\": \"US\",\\n      \"languages\": [\\\\\\n        \"en-US\"\\\\\\n      ]\\n    },\\n    \"removeBase64Images\": true,\\n    \"blockAds\": true,\\n    \"proxy\": \"basic\"\\n  }\\n}\\'\\n```\\n\\n200\\n\\n400\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"id\": \"<string>\"\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Body\\n\\napplication/json\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-urls)\\n\\nurls\\n\\nstring\\\\[\\\\]\\n\\nrequired\\n\\nThe URLs to extract data from. URLs should be in glob format.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-prompt)\\n\\nprompt\\n\\nstring\\n\\nPrompt to guide the extraction process\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-schema)\\n\\nschema\\n\\nobject\\n\\nSchema to define the structure of the extracted data\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-schema-property1)\\n\\nschema.property1\\n\\nstring\\n\\nrequired\\n\\nDescription of property1\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-schema-property2)\\n\\nschema.property2\\n\\ninteger\\n\\nrequired\\n\\nDescription of property2\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-enable-web-search)\\n\\nenableWebSearch\\n\\nboolean\\n\\ndefault:false\\n\\nWhen true, the extraction will use web search to find additional data\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-ignore-sitemap)\\n\\nignoreSitemap\\n\\nboolean\\n\\ndefault:false\\n\\nWhen true, sitemap.xml files will be ignored during website scanning\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-include-subdomains)\\n\\nincludeSubdomains\\n\\nboolean\\n\\ndefault:true\\n\\nWhen true, subdomains of the provided URLs will also be scanned\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-show-sources)\\n\\nshowSources\\n\\nboolean\\n\\ndefault:false\\n\\nWhen true, the sources used to extract the data will be included in the response as `sources` key\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options)\\n\\nscrapeOptions\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options-formats)\\n\\nscrapeOptions.formats\\n\\nenum<string>\\\\[\\\\]\\n\\nFormats to include in the output.\\n\\nAvailable options:\\n\\n`markdown`,\\n\\n`html`,\\n\\n`rawHtml`,\\n\\n`links`,\\n\\n`screenshot`,\\n\\n`screenshot@fullPage`,\\n\\n`json`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options-only-main-content)\\n\\nscrapeOptions.onlyMainContent\\n\\nboolean\\n\\ndefault:true\\n\\nOnly return the main content of the page excluding headers, navs, footers, etc.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options-include-tags)\\n\\nscrapeOptions.includeTags\\n\\nstring\\\\[\\\\]\\n\\nTags to include in the output.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options-exclude-tags)\\n\\nscrapeOptions.excludeTags\\n\\nstring\\\\[\\\\]\\n\\nTags to exclude from the output.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options-headers)\\n\\nscrapeOptions.headers\\n\\nobject\\n\\nHeaders to send with the request. Can be used to send cookies, user-agent, etc.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options-wait-for)\\n\\nscrapeOptions.waitFor\\n\\ninteger\\n\\ndefault:0\\n\\nSpecify a delay in milliseconds before fetching the content, allowing the page sufficient time to load.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options-mobile)\\n\\nscrapeOptions.mobile\\n\\nboolean\\n\\ndefault:false\\n\\nSet to true if you want to emulate scraping from a mobile device. Useful for testing responsive pages and taking mobile screenshots.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options-skip-tls-verification)\\n\\nscrapeOptions.skipTlsVerification\\n\\nboolean\\n\\ndefault:false\\n\\nSkip TLS certificate verification when making requests\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options-timeout)\\n\\nscrapeOptions.timeout\\n\\ninteger\\n\\ndefault:30000\\n\\nTimeout in milliseconds for the request\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options-json-options)\\n\\nscrapeOptions.jsonOptions\\n\\nobject\\n\\nExtract object\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options-json-options-schema)\\n\\nscrapeOptions.jsonOptions.schema\\n\\nobject\\n\\nThe schema to use for the extraction (Optional)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options-json-options-system-prompt)\\n\\nscrapeOptions.jsonOptions.systemPrompt\\n\\nstring\\n\\nThe system prompt to use for the extraction (Optional)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options-json-options-prompt)\\n\\nscrapeOptions.jsonOptions.prompt\\n\\nstring\\n\\nThe prompt to use for the extraction without a schema (Optional)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options-actions)\\n\\nscrapeOptions.actions\\n\\nobject\\\\[\\\\]\\n\\nActions to perform on the page before grabbing the content\\n\\n- Wait\\n- Screenshot\\n- Click\\n- Write text\\n- Press a key\\n- Scroll\\n- Scrape\\n- Execute JavaScript\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options-actions-type)\\n\\nscrapeOptions.actions.type\\n\\nenum<string>\\n\\nrequired\\n\\nWait for a specified amount of milliseconds\\n\\nAvailable options:\\n\\n`wait`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options-actions-milliseconds)\\n\\nscrapeOptions.actions.milliseconds\\n\\ninteger\\n\\nNumber of milliseconds to wait\\n\\nRequired range: `x >= 1`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options-actions-selector)\\n\\nscrapeOptions.actions.selector\\n\\nstring\\n\\nQuery selector to find the element by\\n\\nExample:\\n\\n`\"#my-element\"`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options-location)\\n\\nscrapeOptions.location\\n\\nobject\\n\\nLocation settings for the request. When specified, this will use an appropriate proxy if available and emulate the corresponding language and timezone settings. Defaults to \\'US\\' if not specified.\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options-location-country)\\n\\nscrapeOptions.location.country\\n\\nstring\\n\\ndefault:US\\n\\nISO 3166-1 alpha-2 country code (e.g., \\'US\\', \\'AU\\', \\'DE\\', \\'JP\\')\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options-location-languages)\\n\\nscrapeOptions.location.languages\\n\\nstring\\\\[\\\\]\\n\\nPreferred languages and locales for the request in order of priority. Defaults to the language of the specified location. See [https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Language](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Language)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options-remove-base64-images)\\n\\nscrapeOptions.removeBase64Images\\n\\nboolean\\n\\nRemoves all base 64 images from the output, which may be overwhelmingly long. The image\\'s alt text remains in the output, but the URL is replaced with a placeholder.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options-block-ads)\\n\\nscrapeOptions.blockAds\\n\\nboolean\\n\\ndefault:true\\n\\nEnables ad-blocking and cookie popup blocking.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#body-scrape-options-proxy)\\n\\nscrapeOptions.proxy\\n\\nenum<string>\\n\\nSpecifies the type of proxy to use.\\n\\n- **basic**: Proxies for scraping sites with none to basic anti-bot solutions. Fast and usually works.\\n- **stealth**: Stealth proxies for scraping sites with advanced anti-bot solutions. Slower, but more reliable on certain sites.\\n\\nIf you do not specify a proxy, Firecrawl will automatically attempt to determine which one you need based on the target site.\\n\\nAvailable options:\\n\\n`basic`,\\n\\n`stealth`\\n\\n#### Response\\n\\n200\\n\\n200400500\\n\\napplication/json\\n\\nSuccessful extraction\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#response-success)\\n\\nsuccess\\n\\nboolean\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract#response-id)\\n\\nid\\n\\nstring\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/api-reference/endpoint/extract.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/extract)\\n\\n[Map](https://docs.firecrawl.dev/api-reference/endpoint/map) [Get Extract Status](https://docs.firecrawl.dev/api-reference/endpoint/extract-get)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/extract \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"urls\": [\\\\\\n    \"<string>\"\\\\\\n  ],\\n  \"prompt\": \"<string>\",\\n  \"schema\": {\\n    \"property1\": \"<string>\",\\n    \"property2\": 123\\n  },\\n  \"enableWebSearch\": false,\\n  \"ignoreSitemap\": false,\\n  \"includeSubdomains\": true,\\n  \"showSources\": false,\\n  \"scrapeOptions\": {\\n    \"formats\": [\\\\\\n      \"markdown\"\\\\\\n    ],\\n    \"onlyMainContent\": true,\\n    \"includeTags\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"excludeTags\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"headers\": {},\\n    \"waitFor\": 0,\\n    \"mobile\": false,\\n    \"skipTlsVerification\": false,\\n    \"timeout\": 30000,\\n    \"jsonOptions\": {\\n      \"schema\": {},\\n      \"systemPrompt\": \"<string>\",\\n      \"prompt\": \"<string>\"\\n    },\\n    \"actions\": [\\\\\\n      {\\\\\\n        \"type\": \"wait\",\\\\\\n        \"milliseconds\": 2,\\\\\\n        \"selector\": \"#my-element\"\\\\\\n      }\\\\\\n    ],\\n    \"location\": {\\n      \"country\": \"US\",\\n      \"languages\": [\\\\\\n        \"en-US\"\\\\\\n      ]\\n    },\\n    \"removeBase64Images\": true,\\n    \"blockAds\": true,\\n    \"proxy\": \"basic\"\\n  }\\n}\\'\\n```\\n\\n200\\n\\n400\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"id\": \"<string>\"\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/introduction',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nGet Started\\n\\nQuickstart\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\n![Hero Light](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/images/hero.png)\\n\\n## [\\u200b](https://docs.firecrawl.dev/introduction\\\\#welcome-to-firecrawl)  Welcome to Firecrawl\\n\\n[Firecrawl](https://firecrawl.dev/?ref=github) is an API service that takes a URL, crawls it, and converts it into clean markdown. We crawl all accessible subpages and give you clean markdown for each. No sitemap required.\\n\\n## [\\u200b](https://docs.firecrawl.dev/introduction\\\\#how-to-use-it%3F)  How to use it?\\n\\nWe provide an easy to use API with our hosted version. You can find the playground and documentation [here](https://firecrawl.dev/playground). You can also self host the backend if youâ€™d like.\\n\\nCheck out the following resources to get started:\\n\\n- [x] **API**: [Documentation](https://docs.firecrawl.dev/api-reference/introduction)\\n- [x] **SDKs**: [Python](https://docs.firecrawl.dev/sdks/python), [Node](https://docs.firecrawl.dev/sdks/node), [Go](https://docs.firecrawl.dev/sdks/go), [Rust](https://docs.firecrawl.dev/sdks/rust)\\n- [x] **LLM Frameworks**: [Langchain (python)](https://python.langchain.com/docs/integrations/document_loaders/firecrawl/), [Langchain (js)](https://js.langchain.com/docs/integrations/document_loaders/web_loaders/firecrawl), [Llama Index](https://docs.llamaindex.ai/en/latest/examples/data_connectors/WebPageDemo/#using-firecrawl-reader), [Crew.ai](https://docs.crewai.com/), [Composio](https://composio.dev/tools/firecrawl/all), [PraisonAI](https://docs.praison.ai/firecrawl/), [Superinterface](https://superinterface.ai/docs/assistants/functions/firecrawl), [Vectorize](https://docs.vectorize.io/integrations/source-connectors/firecrawl)\\n- [x] **Low-code Frameworks**: [Dify](https://dify.ai/blog/dify-ai-blog-integrated-with-firecrawl), [Langflow](https://docs.langflow.org/), [Flowise AI](https://docs.flowiseai.com/integrations/langchain/document-loaders/firecrawl), [Cargo](https://docs.getcargo.io/integration/firecrawl), [Pipedream](https://pipedream.com/apps/firecrawl/)\\n- [x] **Others**: [Zapier](https://zapier.com/apps/firecrawl/integrations), [Pabbly Connect](https://www.pabbly.com/connect/integrations/firecrawl/)\\n- [ ]  Want an SDK or Integration? Let us know by opening an issue.\\n\\n**Self-host:** To self-host refer to guide [here](https://docs.firecrawl.dev/contributing/self-host).\\n\\n### [\\u200b](https://docs.firecrawl.dev/introduction\\\\#api-key)  API Key\\n\\nTo use the API, you need to sign up on [Firecrawl](https://firecrawl.dev/) and get an API key.\\n\\n### [\\u200b](https://docs.firecrawl.dev/introduction\\\\#features)  Features\\n\\n- [**Scrape**](https://docs.firecrawl.dev/introduction#scraping): scrapes a URL and get its content in LLM-ready format (markdown, structured data via [LLM Extract](https://docs.firecrawl.dev/introduction#extraction), screenshot, html)\\n- [**Crawl**](https://docs.firecrawl.dev/introduction#crawling): scrapes all the URLs of a web page and return content in LLM-ready format\\n- [**Map**](https://docs.firecrawl.dev/features/map): input a website and get all the website urls - extremely fast\\n- [**Extract**](https://docs.firecrawl.dev/features/extract): get structured data from single page, multiple pages or entire websites with AI.\\n\\n### [\\u200b](https://docs.firecrawl.dev/introduction\\\\#powerful-capabilities)  Powerful Capabilities\\n\\n- **LLM-ready formats**: markdown, structured data, screenshot, HTML, links, metadata\\n- **The hard stuff**: proxies, anti-bot mechanisms, dynamic content (js-rendered), output parsing, orchestration\\n- **Customizability**: exclude tags, crawl behind auth walls with custom headers, max crawl depth, etcâ€¦\\n- **Media parsing**: pdfs, docx, images.\\n- **Reliability first**: designed to get the data you need - no matter how hard it is.\\n- **Actions**: click, scroll, input, wait and more before extracting data\\n\\nYou can find all of Firecrawlâ€™s capabilities and how to use them in our [documentation](https://docs.firecrawl.dev/)\\n\\n## [\\u200b](https://docs.firecrawl.dev/introduction\\\\#crawling)  Crawling\\n\\nUsed to crawl a URL and all accessible subpages. This submits a crawl job and returns a job ID to check the status of the crawl.\\n\\n### [\\u200b](https://docs.firecrawl.dev/introduction\\\\#installation)  Installation\\n\\nPython\\n\\nNode\\n\\nGo\\n\\nRust\\n\\nCopy\\n\\n```bash\\npip install firecrawl-py\\n\\n```\\n\\n### [\\u200b](https://docs.firecrawl.dev/introduction\\\\#usage)  Usage\\n\\nPython\\n\\nNode\\n\\nGo\\n\\nRust\\n\\ncURL\\n\\nCopy\\n\\n```python\\nfrom firecrawl import FirecrawlApp\\n\\napp = FirecrawlApp(api_key=\"fc-YOUR_API_KEY\")\\n\\n# Crawl a website:\\ncrawl_status = app.crawl_url(\\n  \\'https://firecrawl.dev\\',\\n  params={\\n    \\'limit\\': 100,\\n    \\'scrapeOptions\\': {\\'formats\\': [\\'markdown\\', \\'html\\']}\\n  },\\n  poll_interval=30\\n)\\nprint(crawl_status)\\n\\n```\\n\\nIf youâ€™re using cURL or `async crawl` functions on SDKs, this will return an `ID` where you can use to check the status of the crawl.\\n\\nCopy\\n\\n```json\\n{\\n  \"success\": true,\\n  \"id\": \"123-456-789\",\\n  \"url\": \"https://api.firecrawl.dev/v1/crawl/123-456-789\"\\n}\\n\\n```\\n\\n### [\\u200b](https://docs.firecrawl.dev/introduction\\\\#check-crawl-job)  Check Crawl Job\\n\\nUsed to check the status of a crawl job and get its result.\\n\\nPython\\n\\nNode\\n\\nGo\\n\\nRust\\n\\ncURL\\n\\nCopy\\n\\n```python\\ncrawl_status = app.check_crawl_status(\"<crawl_id>\")\\nprint(crawl_status)\\n\\n```\\n\\n#### [\\u200b](https://docs.firecrawl.dev/introduction\\\\#response)  Response\\n\\nThe response will be different depending on the status of the crawl. For not completed or large responses exceeding 10MB, a `next` URL parameter is provided. You must request this URL to retrieve the next 10MB of data. If the `next` parameter is absent, it indicates the end of the crawl data.\\n\\nScraping\\n\\nCompleted\\n\\nCopy\\n\\n```json\\n{\\n  \"status\": \"scraping\",\\n  \"total\": 36,\\n  \"completed\": 10,\\n  \"creditsUsed\": 10,\\n  \"expiresAt\": \"2024-00-00T00:00:00.000Z\",\\n  \"next\": \"https://api.firecrawl.dev/v1/crawl/123-456-789?skip=10\",\\n  \"data\": [\\\\\\n    {\\\\\\n      \"markdown\": \"[Firecrawl Docs home page![light logo](https://mintlify.s3-us-west-1.amazonaws.com/firecrawl/logo/light.svg)!...\",\\\\\\n      \"html\": \"<!DOCTYPE html><html lang=\\\\\"en\\\\\" class=\\\\\"js-focus-visible lg:[--scroll-mt:9.5rem]\\\\\" data-js-focus-visible=\\\\\"\\\\\">...\",\\\\\\n      \"metadata\": {\\\\\\n        \"title\": \"Build a \\'Chat with website\\' using Groq Llama 3 | Firecrawl\",\\\\\\n        \"language\": \"en\",\\\\\\n        \"sourceURL\": \"https://docs.firecrawl.dev/learn/rag-llama3\",\\\\\\n        \"description\": \"Learn how to use Firecrawl, Groq Llama 3, and Langchain to build a \\'Chat with your website\\' bot.\",\\\\\\n        \"ogLocaleAlternate\": [],\\\\\\n        \"statusCode\": 200\\\\\\n      }\\\\\\n    },\\\\\\n    ...\\\\\\n  ]\\\\\\n}\\\\\\n\\\\\\n```\\\\\\n\\\\\\n## [\\u200b](https://docs.firecrawl.dev/introduction\\\\#scraping)  Scraping\\\\\\n\\\\\\nTo scrape a single URL, use the `scrape_url` method. It takes the URL as a parameter and returns the scraped data as a dictionary.\\\\\\n\\\\\\nPython\\\\\\n\\\\\\nNode\\\\\\n\\\\\\nGo\\\\\\n\\\\\\nRust\\\\\\n\\\\\\ncURL\\\\\\n\\\\\\nCopy\\\\\\n\\\\\\n```python\\\\\\nfrom firecrawl import FirecrawlApp\\\\\\n\\\\\\napp = FirecrawlApp(api_key=\"fc-YOUR_API_KEY\")\\\\\\n\\\\\\n# Scrape a website:\\\\\\nscrape_result = app.scrape_url(\\'firecrawl.dev\\', params={\\'formats\\': [\\'markdown\\', \\'html\\']})\\\\\\nprint(scrape_result)\\\\\\n\\\\\\n```\\\\\\n\\\\\\n### [\\u200b](https://docs.firecrawl.dev/introduction\\\\#response-2)  Response\\\\\\n\\\\\\nSDKs will return the data object directly. cURL will return the payload exactly as shown below.\\\\\\n\\\\\\nCopy\\\\\\n\\\\\\n```json\\\\\\n{\\\\\\n  \"success\": true,\\\\\\n  \"data\" : {\\\\\\n    \"markdown\": \"Launch Week I is here! [See our Day 2 Release ðŸš€](https://www.firecrawl.dev/blog/launch-week-i-day-2-doubled-rate-limits)[ðŸ’¥ Get 2 months free...\",\\\\\\n    \"html\": \"<!DOCTYPE html><html lang=\\\\\"en\\\\\" class=\\\\\"light\\\\\" style=\\\\\"color-scheme: light;\\\\\"><body class=\\\\\"__variable_36bd41 __variable_d7dc5d font-inter ...\",\\\\\\n    \"metadata\": {\\\\\\n      \"title\": \"Home - Firecrawl\",\\\\\\n      \"description\": \"Firecrawl crawls and converts any website into clean markdown.\",\\\\\\n      \"language\": \"en\",\\\\\\n      \"keywords\": \"Firecrawl,Markdown,Data,Mendable,Langchain\",\\\\\\n      \"robots\": \"follow, index\",\\\\\\n      \"ogTitle\": \"Firecrawl\",\\\\\\n      \"ogDescription\": \"Turn any website into LLM-ready data.\",\\\\\\n      \"ogUrl\": \"https://www.firecrawl.dev/\",\\\\\\n      \"ogImage\": \"https://www.firecrawl.dev/og.png?123\",\\\\\\n      \"ogLocaleAlternate\": [],\\\\\\n      \"ogSiteName\": \"Firecrawl\",\\\\\\n      \"sourceURL\": \"https://firecrawl.dev\",\\\\\\n      \"statusCode\": 200\\\\\\n    }\\\\\\n  }\\\\\\n}\\\\\\n\\\\\\n```\\\\\\n\\\\\\n## [\\u200b](https://docs.firecrawl.dev/introduction\\\\#extraction)  Extraction\\\\\\n\\\\\\nWith LLM extraction, you can easily extract structured data from any URL. We support pydantic schemas to make it easier for you too. Here is how you to use it:\\\\\\n\\\\\\nv1 is only supported on node, python and cURL at this time.\\\\\\n\\\\\\nPython\\\\\\n\\\\\\nNode\\\\\\n\\\\\\ncURL\\\\\\n\\\\\\nCopy\\\\\\n\\\\\\n```python\\\\\\nfrom firecrawl import FirecrawlApp\\\\\\nfrom pydantic import BaseModel, Field\\\\\\n\\\\\\n# Initialize the FirecrawlApp with your API key\\\\\\napp = FirecrawlApp(api_key=\\'your_api_key\\')\\\\\\n\\\\\\nclass ExtractSchema(BaseModel):\\\\\\n    company_mission: str\\\\\\n    supports_sso: bool\\\\\\n    is_open_source: bool\\\\\\n    is_in_yc: bool\\\\\\n\\\\\\ndata = app.scrape_url(\\'https://docs.firecrawl.dev/\\', {\\\\\\n    \\'formats\\': [\\'json\\'],\\\\\\n    \\'jsonOptions\\': {\\\\\\n        \\'schema\\': ExtractSchema.model_json_schema(),\\\\\\n    }\\\\\\n})\\\\\\nprint(data[\"json\"])\\\\\\n\\\\\\n```\\\\\\n\\\\\\nOutput:\\\\\\n\\\\\\nJSON\\\\\\n\\\\\\nCopy\\\\\\n\\\\\\n```json\\\\\\n{\\\\\\n    \"success\": true,\\\\\\n    \"data\": {\\\\\\n      \"json\": {\\\\\\n        \"company_mission\": \"Train a secure AI on your technical resources that answers customer and employee questions so your team doesn\\'t have to\",\\\\\\n        \"supports_sso\": true,\\\\\\n        \"is_open_source\": false,\\\\\\n        \"is_in_yc\": true\\\\\\n      },\\\\\\n      \"metadata\": {\\\\\\n        \"title\": \"Mendable\",\\\\\\n        \"description\": \"Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide\",\\\\\\n        \"robots\": \"follow, index\",\\\\\\n        \"ogTitle\": \"Mendable\",\\\\\\n        \"ogDescription\": \"Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide\",\\\\\\n        \"ogUrl\": \"https://docs.firecrawl.dev/\",\\\\\\n        \"ogImage\": \"https://docs.firecrawl.dev/mendable_new_og1.png\",\\\\\\n        \"ogLocaleAlternate\": [],\\\\\\n        \"ogSiteName\": \"Mendable\",\\\\\\n        \"sourceURL\": \"https://docs.firecrawl.dev/\"\\\\\\n      },\\\\\\n    }\\\\\\n}\\\\\\n\\\\\\n```\\\\\\n\\\\\\n### [\\u200b](https://docs.firecrawl.dev/introduction\\\\#extracting-without-schema-new)  Extracting without schema (New)\\\\\\n\\\\\\nYou can now extract without a schema by just passing a `prompt` to the endpoint. The llm chooses the structure of the data.\\\\\\n\\\\\\ncURL\\\\\\n\\\\\\nCopy\\\\\\n\\\\\\n```bash\\\\\\ncurl -X POST https://api.firecrawl.dev/v1/scrape \\\\\\\\\\n    -H \\'Content-Type: application/json\\' \\\\\\\\\\n    -H \\'Authorization: Bearer YOUR_API_KEY\\' \\\\\\\\\\n    -d \\'{\\\\\\n      \"url\": \"https://docs.firecrawl.dev/\",\\\\\\n      \"formats\": [\"json\"],\\\\\\n      \"jsonOptions\": {\\\\\\n        \"prompt\": \"Extract the company mission from the page.\"\\\\\\n      }\\\\\\n    }\\'\\\\\\n\\\\\\n```\\\\\\n\\\\\\nOutput:\\\\\\n\\\\\\nJSON\\\\\\n\\\\\\nCopy\\\\\\n\\\\\\n```json\\\\\\n{\\\\\\n    \"success\": true,\\\\\\n    \"data\": {\\\\\\n      \"json\": {\\\\\\n        \"company_mission\": \"Train a secure AI on your technical resources that answers customer and employee questions so your team doesn\\'t have to\",\\\\\\n      },\\\\\\n      \"metadata\": {\\\\\\n        \"title\": \"Mendable\",\\\\\\n        \"description\": \"Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide\",\\\\\\n        \"robots\": \"follow, index\",\\\\\\n        \"ogTitle\": \"Mendable\",\\\\\\n        \"ogDescription\": \"Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide\",\\\\\\n        \"ogUrl\": \"https://docs.firecrawl.dev/\",\\\\\\n        \"ogImage\": \"https://docs.firecrawl.dev/mendable_new_og1.png\",\\\\\\n        \"ogLocaleAlternate\": [],\\\\\\n        \"ogSiteName\": \"Mendable\",\\\\\\n        \"sourceURL\": \"https://docs.firecrawl.dev/\"\\\\\\n      },\\\\\\n    }\\\\\\n}\\\\\\n\\\\\\n```\\\\\\n\\\\\\n### [\\u200b](https://docs.firecrawl.dev/introduction\\\\#extraction-v0)  Extraction (v0)\\\\\\n\\\\\\nPython\\\\\\n\\\\\\nJavaScript\\\\\\n\\\\\\nGo\\\\\\n\\\\\\nRust\\\\\\n\\\\\\ncURL\\\\\\n\\\\\\nCopy\\\\\\n\\\\\\n```python\\\\\\n\\\\\\napp = FirecrawlApp(version=\"v0\")\\\\\\n\\\\\\nclass ArticleSchema(BaseModel):\\\\\\n    title: str\\\\\\n    points: int\\\\\\n    by: str\\\\\\n    commentsURL: str\\\\\\n\\\\\\nclass TopArticlesSchema(BaseModel):\\\\\\ntop: List[ArticleSchema] = Field(..., max_items=5, description=\"Top 5 stories\")\\\\\\n\\\\\\ndata = app.scrape_url(\\'https://news.ycombinator.com\\', {\\\\\\n\\'extractorOptions\\': {\\\\\\n\\'extractionSchema\\': TopArticlesSchema.model_json_schema(),\\\\\\n\\'mode\\': \\'llm-extraction\\'\\\\\\n},\\\\\\n\\'pageOptions\\':{\\\\\\n\\'onlyMainContent\\': True\\\\\\n}\\\\\\n})\\\\\\nprint(data[\"llm_extraction\"])\\\\\\n\\\\\\n```\\\\\\n\\\\\\n## [\\u200b](https://docs.firecrawl.dev/introduction\\\\#interacting-with-the-page-with-actions)  Interacting with the page with Actions\\\\\\n\\\\\\nFirecrawl allows you to perform various actions on a web page before scraping its content. This is particularly useful for interacting with dynamic content, navigating through pages, or accessing content that requires user interaction.\\\\\\n\\\\\\nHere is an example of how to use actions to navigate to google.com, search for Firecrawl, click on the first result, and take a screenshot.\\\\\\n\\\\\\nIt is important to almost always use the `wait` action before/after executing other actions to give enough time for the page to load.\\\\\\n\\\\\\n### [\\u200b](https://docs.firecrawl.dev/introduction\\\\#example)  Example\\\\\\n\\\\\\nPython\\\\\\n\\\\\\nNode\\\\\\n\\\\\\ncURL\\\\\\n\\\\\\nCopy\\\\\\n\\\\\\n```python\\\\\\nfrom firecrawl import FirecrawlApp\\\\\\n\\\\\\napp = FirecrawlApp(api_key=\"fc-YOUR_API_KEY\")\\\\\\n\\\\\\n# Scrape a website:\\\\\\nscrape_result = app.scrape_url(\\'firecrawl.dev\\',\\\\\\n    params={\\\\\\n        \\'formats\\': [\\'markdown\\', \\'html\\'],\\\\\\n        \\'actions\\': [\\\\\\n            {\"type\": \"wait\", \"milliseconds\": 2000},\\\\\\n            {\"type\": \"click\", \"selector\": \"textarea[title=\\\\\"Search\\\\\"]\"},\\\\\\n            {\"type\": \"wait\", \"milliseconds\": 2000},\\\\\\n            {\"type\": \"write\", \"text\": \"firecrawl\"},\\\\\\n            {\"type\": \"wait\", \"milliseconds\": 2000},\\\\\\n            {\"type\": \"press\", \"key\": \"ENTER\"},\\\\\\n            {\"type\": \"wait\", \"milliseconds\": 3000},\\\\\\n            {\"type\": \"click\", \"selector\": \"h3\"},\\\\\\n            {\"type\": \"wait\", \"milliseconds\": 3000},\\\\\\n            {\"type\": \"scrape\"},\\\\\\n            {\"type\": \"screenshot\"}\\\\\\n        ]\\\\\\n    }\\\\\\n)\\\\\\nprint(scrape_result)\\\\\\n\\\\\\n```\\\\\\n\\\\\\n### [\\u200b](https://docs.firecrawl.dev/introduction\\\\#output)  Output\\\\\\n\\\\\\nJSON\\\\\\n\\\\\\nCopy\\\\\\n\\\\\\n```json\\\\\\n{\\\\\\n  \"success\": true,\\\\\\n  \"data\": {\\\\\\n    \"markdown\": \"Our first Launch Week is over! [See the recap ðŸš€](blog/firecrawl-launch-week-1-recap)...\",\\\\\\n    \"actions\": {\\\\\\n      \"screenshots\": [\\\\\\n        \"https://alttmdsdujxrfnakrkyi.supabase.co/storage/v1/object/public/media/screenshot-75ef2d87-31e0-4349-a478-fb432a29e241.png\"\\\\\\n      ],\\\\\\n      \"scrapes\": [\\\\\\n        {\\\\\\n          \"url\": \"https://www.firecrawl.dev/\",\\\\\\n          \"html\": \"<html><body><h1>Firecrawl</h1></body></html>\"\\\\\\n        }\\\\\\n      ]\\\\\\n    },\\\\\\n    \"metadata\": {\\\\\\n      \"title\": \"Home - Firecrawl\",\\\\\\n      \"description\": \"Firecrawl crawls and converts any website into clean markdown.\",\\\\\\n      \"language\": \"en\",\\\\\\n      \"keywords\": \"Firecrawl,Markdown,Data,Mendable,Langchain\",\\\\\\n      \"robots\": \"follow, index\",\\\\\\n      \"ogTitle\": \"Firecrawl\",\\\\\\n      \"ogDescription\": \"Turn any website into LLM-ready data.\",\\\\\\n      \"ogUrl\": \"https://www.firecrawl.dev/\",\\\\\\n      \"ogImage\": \"https://www.firecrawl.dev/og.png?123\",\\\\\\n      \"ogLocaleAlternate\": [],\\\\\\n      \"ogSiteName\": \"Firecrawl\",\\\\\\n      \"sourceURL\": \"http://google.com\",\\\\\\n      \"statusCode\": 200\\\\\\n    }\\\\\\n  }\\\\\\n}\\\\\\n\\\\\\n```\\\\\\n\\\\\\n## [\\u200b](https://docs.firecrawl.dev/introduction\\\\#open-source-vs-cloud)  Open Source vs Cloud\\\\\\n\\\\\\nFirecrawl is open source available under the [AGPL-3.0 license](https://github.com/mendableai/firecrawl/blob/main/LICENSE).\\\\\\n\\\\\\nTo deliver the best possible product, we offer a hosted version of Firecrawl alongside our open-source offering. The cloud solution allows us to continuously innovate and maintain a high-quality, sustainable service for all users.\\\\\\n\\\\\\nFirecrawl Cloud is available at [firecrawl.dev](https://firecrawl.dev/) and offers a range of features that are not available in the open source version:\\\\\\n\\\\\\n![Firecrawl Cloud vs Open Source](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/images/open-source-cloud.png)\\\\\\n\\\\\\n## [\\u200b](https://docs.firecrawl.dev/introduction\\\\#contributing)  Contributing\\\\\\n\\\\\\nWe love contributions! Please read our [contributing guide](https://github.com/mendableai/firecrawl/blob/main/CONTRIBUTING.md) before submitting a pull request.\\\\\\n\\\\\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/introduction.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/introduction)\\\\\\n\\\\\\n[Launch Week II (New)](https://docs.firecrawl.dev/launch-week)\\\\\\n\\\\\\nOn this page\\\\\\n\\\\\\n- [Welcome to Firecrawl](https://docs.firecrawl.dev/introduction#welcome-to-firecrawl)\\\\\\n- [How to use it?](https://docs.firecrawl.dev/introduction#how-to-use-it%3F)\\\\\\n- [API Key](https://docs.firecrawl.dev/introduction#api-key)\\\\\\n- [Features](https://docs.firecrawl.dev/introduction#features)\\\\\\n- [Powerful Capabilities](https://docs.firecrawl.dev/introduction#powerful-capabilities)\\\\\\n- [Crawling](https://docs.firecrawl.dev/introduction#crawling)\\\\\\n- [Installation](https://docs.firecrawl.dev/introduction#installation)\\\\\\n- [Usage](https://docs.firecrawl.dev/introduction#usage)\\\\\\n- [Check Crawl Job](https://docs.firecrawl.dev/introduction#check-crawl-job)\\\\\\n- [Response](https://docs.firecrawl.dev/introduction#response)\\\\\\n- [Scraping](https://docs.firecrawl.dev/introduction#scraping)\\\\\\n- [Response](https://docs.firecrawl.dev/introduction#response-2)\\\\\\n- [Extraction](https://docs.firecrawl.dev/introduction#extraction)\\\\\\n- [Extracting without schema (New)](https://docs.firecrawl.dev/introduction#extracting-without-schema-new)\\\\\\n- [Extraction (v0)](https://docs.firecrawl.dev/introduction#extraction-v0)\\\\\\n- [Interacting with the page with Actions](https://docs.firecrawl.dev/introduction#interacting-with-the-page-with-actions)\\\\\\n- [Example](https://docs.firecrawl.dev/introduction#example)\\\\\\n- [Output](https://docs.firecrawl.dev/introduction#output)\\\\\\n- [Open Source vs Cloud](https://docs.firecrawl.dev/introduction#open-source-vs-cloud)\\\\\\n- [Contributing](https://docs.firecrawl.dev/introduction#contributing)\\\\\\n\\\\\\n![Hero Light](https://docs.firecrawl.dev/introduction)'},\n",
              " {'url': 'https://docs.firecrawl.dev/api-reference/endpoint/llm-extract',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/api-reference/endpoint/llm-extract.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/llm-extract)'},\n",
              " {'url': 'https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nCrawl\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nPOST\\n\\n/\\n\\ncrawl\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v0/crawl \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"url\": \"<string>\",\\n  \"crawlerOptions\": {\\n    \"includes\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"excludes\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"generateImgAltText\": false,\\n    \"returnOnlyUrls\": false,\\n    \"maxDepth\": 123,\\n    \"mode\": \"default\",\\n    \"ignoreSitemap\": false,\\n    \"limit\": 10000,\\n    \"allowBackwardCrawling\": false,\\n    \"allowExternalContentLinks\": false\\n  },\\n  \"pageOptions\": {\\n    \"headers\": {},\\n    \"includeHtml\": false,\\n    \"includeRawHtml\": false,\\n    \"onlyIncludeTags\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"onlyMainContent\": false,\\n    \"removeTags\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"replaceAllPathsWithAbsolutePaths\": false,\\n    \"screenshot\": false,\\n    \"fullPageScreenshot\": false,\\n    \"waitFor\": 0\\n  }\\n}\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"jobId\": \"<string>\"\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Body\\n\\napplication/json\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#body-url)\\n\\nurl\\n\\nstring\\n\\nrequired\\n\\nThe base URL to start crawling from\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#body-crawler-options)\\n\\ncrawlerOptions\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#body-crawler-options-includes)\\n\\ncrawlerOptions.includes\\n\\nstring\\\\[\\\\]\\n\\nURL patterns to include\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#body-crawler-options-excludes)\\n\\ncrawlerOptions.excludes\\n\\nstring\\\\[\\\\]\\n\\nURL patterns to exclude\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#body-crawler-options-generate-img-alt-text)\\n\\ncrawlerOptions.generateImgAltText\\n\\nboolean\\n\\ndefault:false\\n\\nGenerate alt text for images using LLMs (must have a paid plan)\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#body-crawler-options-return-only-urls)\\n\\ncrawlerOptions.returnOnlyUrls\\n\\nboolean\\n\\ndefault:false\\n\\nIf true, returns only the URLs as a list on the crawl status. Attention: the return response will be a list of URLs inside the data, not a list of documents.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#body-crawler-options-max-depth)\\n\\ncrawlerOptions.maxDepth\\n\\ninteger\\n\\nMaximum depth to crawl relative to the entered URL. A maxDepth of 0 scrapes only the entered URL. A maxDepth of 1 scrapes the entered URL and all pages one level deep. A maxDepth of 2 scrapes the entered URL and all pages up to two levels deep. Higher values follow the same pattern.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#body-crawler-options-mode)\\n\\ncrawlerOptions.mode\\n\\nenum<string>\\n\\ndefault:default\\n\\nThe crawling mode to use. Fast mode crawls 4x faster websites without sitemap, but may not be as accurate and shouldn\\'t be used in heavy js-rendered websites.\\n\\nAvailable options:\\n\\n`default`,\\n\\n`fast`\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#body-crawler-options-ignore-sitemap)\\n\\ncrawlerOptions.ignoreSitemap\\n\\nboolean\\n\\ndefault:false\\n\\nIgnore the website sitemap when crawling\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#body-crawler-options-limit)\\n\\ncrawlerOptions.limit\\n\\ninteger\\n\\ndefault:10000\\n\\nMaximum number of pages to crawl\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#body-crawler-options-allow-backward-crawling)\\n\\ncrawlerOptions.allowBackwardCrawling\\n\\nboolean\\n\\ndefault:false\\n\\nEnables the crawler to navigate from a specific URL to previously linked pages. For instance, from \\'example.com/product/123\\' back to \\'example.com/product\\'\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#body-crawler-options-allow-external-content-links)\\n\\ncrawlerOptions.allowExternalContentLinks\\n\\nboolean\\n\\ndefault:false\\n\\nAllows the crawler to follow links to external websites.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#body-page-options)\\n\\npageOptions\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#body-page-options-headers)\\n\\npageOptions.headers\\n\\nobject\\n\\nHeaders to send with the request. Can be used to send cookies, user-agent, etc.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#body-page-options-include-html)\\n\\npageOptions.includeHtml\\n\\nboolean\\n\\ndefault:false\\n\\nInclude the HTML version of the content on page. Will output a html key in the response.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#body-page-options-include-raw-html)\\n\\npageOptions.includeRawHtml\\n\\nboolean\\n\\ndefault:false\\n\\nInclude the raw HTML content of the page. Will output a rawHtml key in the response.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#body-page-options-only-include-tags)\\n\\npageOptions.onlyIncludeTags\\n\\nstring\\\\[\\\\]\\n\\nOnly include tags, classes and ids from the page in the final output. Use comma separated values. Example: \\'script, .ad, #footer\\'\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#body-page-options-only-main-content)\\n\\npageOptions.onlyMainContent\\n\\nboolean\\n\\ndefault:false\\n\\nOnly return the main content of the page excluding headers, navs, footers, etc.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#body-page-options-remove-tags)\\n\\npageOptions.removeTags\\n\\nstring\\\\[\\\\]\\n\\nTags, classes and ids to remove from the page. Use comma separated values. Example: \\'script, .ad, #footer\\'\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#body-page-options-replace-all-paths-with-absolute-paths)\\n\\npageOptions.replaceAllPathsWithAbsolutePaths\\n\\nboolean\\n\\ndefault:false\\n\\nReplace all relative paths with absolute paths for images and links\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#body-page-options-screenshot)\\n\\npageOptions.screenshot\\n\\nboolean\\n\\ndefault:false\\n\\nInclude a screenshot of the top of the page that you are scraping.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#body-page-options-full-page-screenshot)\\n\\npageOptions.fullPageScreenshot\\n\\nboolean\\n\\ndefault:false\\n\\nInclude a full page screenshot of the page that you are scraping.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#body-page-options-wait-for)\\n\\npageOptions.waitFor\\n\\ninteger\\n\\ndefault:0\\n\\nWait x amount of milliseconds for the page to load to fetch content\\n\\n#### Response\\n\\n200\\n\\n200402429500\\n\\napplication/json\\n\\nSuccessful response\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl#response-job-id)\\n\\njobId\\n\\nstring\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/v0/api-reference/endpoint/crawl.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/v0/api-reference/endpoint/crawl)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v0/crawl \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"url\": \"<string>\",\\n  \"crawlerOptions\": {\\n    \"includes\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"excludes\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"generateImgAltText\": false,\\n    \"returnOnlyUrls\": false,\\n    \"maxDepth\": 123,\\n    \"mode\": \"default\",\\n    \"ignoreSitemap\": false,\\n    \"limit\": 10000,\\n    \"allowBackwardCrawling\": false,\\n    \"allowExternalContentLinks\": false\\n  },\\n  \"pageOptions\": {\\n    \"headers\": {},\\n    \"includeHtml\": false,\\n    \"includeRawHtml\": false,\\n    \"onlyIncludeTags\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"onlyMainContent\": false,\\n    \"removeTags\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"replaceAllPathsWithAbsolutePaths\": false,\\n    \"screenshot\": false,\\n    \"fullPageScreenshot\": false,\\n    \"waitFor\": 0\\n  }\\n}\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"jobId\": \"<string>\"\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl-cancel',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nCancel Crawl Job\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nDELETE\\n\\n/\\n\\ncrawl\\n\\n/\\n\\ncancel\\n\\n/\\n\\n{jobId}\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request DELETE \\\\\\n  --url https://api.firecrawl.dev/v0/crawl/cancel/{jobId} \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"status\": \"<string>\"\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl-cancel#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Path Parameters\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl-cancel#parameter-job-id)\\n\\njobId\\n\\nstring\\n\\nrequired\\n\\nID of the crawl job\\n\\n#### Response\\n\\n200\\n\\n200402429500\\n\\napplication/json\\n\\nSuccessful response\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/crawl-cancel#response-status)\\n\\nstatus\\n\\nstring\\n\\nReturns cancelled.\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/v0/api-reference/endpoint/crawl-cancel.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/v0/api-reference/endpoint/crawl-cancel)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request DELETE \\\\\\n  --url https://api.firecrawl.dev/v0/crawl/cancel/{jobId} \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"status\": \"<string>\"\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/v0/api-reference/introduction',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nIntroduction\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\n## [\\u200b](https://docs.firecrawl.dev/v0/api-reference/introduction\\\\#base-url)  Base URL\\n\\nAll requests contain the following base URL:\\n\\nCopy\\n\\n```bash\\nhttps://api.firecrawl.dev\\n\\n```\\n\\n## [\\u200b](https://docs.firecrawl.dev/v0/api-reference/introduction\\\\#authentication)  Authentication\\n\\nFor authentication, itâ€™s required to include an Authorization header. The header should contain `Bearer fc_123456789`, where `fc_123456789` represents your API Key.\\n\\nCopy\\n\\n```bash\\nAuthorization: Bearer fc_123456789\\n\\n```\\n\\n\\u200b\\n\\n## [\\u200b](https://docs.firecrawl.dev/v0/api-reference/introduction\\\\#response-codes)  Response codes\\n\\nFirecrawl employs conventional HTTP status codes to signify the outcome of your requests.\\n\\nTypically, 2xx HTTP status codes denote success, 4xx codes represent failures related to the user, and 5xx codes signal infrastructure problems.\\n\\n| Status | Description |\\n| --- | --- |\\n| 200 | Request was successful. |\\n| 400 | Verify the correctness of the parameters. |\\n| 401 | The API key was not provided. |\\n| 402 | Payment required |\\n| 404 | The requested resource could not be located. |\\n| 429 | The rate limit has been surpassed. |\\n| 5xx | Signifies a server error with Firecrawl. |\\n\\nRefer to the Error Codes section for a detailed explanation of all potential API errors.\\n\\n\\u200b\\n\\n## [\\u200b](https://docs.firecrawl.dev/v0/api-reference/introduction\\\\#rate-limit)  Rate limit\\n\\nThe Firecrawl API has a rate limit to ensure the stability and reliability of the service. The rate limit is applied to all endpoints and is based on the number of requests made within a specific time frame.\\n\\nWhen you exceed the rate limit, you will receive a 429 response code.\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/v0/api-reference/introduction.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/v0/api-reference/introduction)\\n\\nOn this page\\n\\n- [Base URL](https://docs.firecrawl.dev/v0/api-reference/introduction#base-url)\\n- [Authentication](https://docs.firecrawl.dev/v0/api-reference/introduction#authentication)\\n- [Response codes](https://docs.firecrawl.dev/v0/api-reference/introduction#response-codes)\\n- [Rate limit](https://docs.firecrawl.dev/v0/api-reference/introduction#rate-limit)'},\n",
              " {'url': 'https://docs.firecrawl.dev/v0/api-reference/endpoint/search',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nSearch (Beta)\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nPOST\\n\\n/\\n\\nsearch\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v0/search \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"query\": \"<string>\",\\n  \"pageOptions\": {\\n    \"onlyMainContent\": false,\\n    \"fetchPageContent\": true,\\n    \"includeHtml\": false,\\n    \"includeRawHtml\": false\\n  },\\n  \"searchOptions\": {\\n    \"limit\": 123\\n  }\\n}\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"data\": [\\\\\\n    {\\\\\\n      \"url\": \"<string>\",\\\\\\n      \"markdown\": \"<string>\",\\\\\\n      \"content\": \"<string>\",\\\\\\n      \"metadata\": {\\\\\\n        \"title\": \"<string>\",\\\\\\n        \"description\": \"<string>\",\\\\\\n        \"language\": \"<string>\",\\\\\\n        \"sourceURL\": \"<string>\"\\\\\\n      }\\\\\\n    }\\\\\\n  ]\\n}\\n```\\n\\nThe search endpoint combines a search API with the power of Firecrawl to provide a powerful search experience for whatever query.\\n\\nIt automatically searches the web for the query and returns the most relevant results from the top pages in markdown format. The advantage of this endpoint is that it actually scrap each website on the top result so you always get the full content.\\n\\nThis endpoint is currently in beta and is subject to change.\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/search#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Body\\n\\napplication/json\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/search#body-query)\\n\\nquery\\n\\nstring\\n\\nrequired\\n\\nThe query to search for\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/search#body-page-options)\\n\\npageOptions\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/search#body-page-options-only-main-content)\\n\\npageOptions.onlyMainContent\\n\\nboolean\\n\\ndefault:false\\n\\nOnly return the main content of the page excluding headers, navs, footers, etc.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/search#body-page-options-fetch-page-content)\\n\\npageOptions.fetchPageContent\\n\\nboolean\\n\\ndefault:true\\n\\nFetch the content of each page. If false, defaults to a basic fast serp API.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/search#body-page-options-include-html)\\n\\npageOptions.includeHtml\\n\\nboolean\\n\\ndefault:false\\n\\nInclude the HTML version of the content on page. Will output a html key in the response.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/search#body-page-options-include-raw-html)\\n\\npageOptions.includeRawHtml\\n\\nboolean\\n\\ndefault:false\\n\\nInclude the raw HTML content of the page. Will output a rawHtml key in the response.\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/search#body-search-options)\\n\\nsearchOptions\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/search#body-search-options-limit)\\n\\nsearchOptions.limit\\n\\ninteger\\n\\nMaximum number of results. Max is 20 during beta.\\n\\n#### Response\\n\\n200\\n\\n200402429500\\n\\napplication/json\\n\\nSuccessful response\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/search#response-success)\\n\\nsuccess\\n\\nboolean\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/search#response-data)\\n\\ndata\\n\\nobject\\\\[\\\\]\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/search#response-data-url)\\n\\ndata.url\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/search#response-data-markdown)\\n\\ndata.markdown\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/search#response-data-content)\\n\\ndata.content\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/search#response-data-metadata)\\n\\ndata.metadata\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/search#response-data-metadata-title)\\n\\ndata.metadata.title\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/search#response-data-metadata-description)\\n\\ndata.metadata.description\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/search#response-data-metadata-language)\\n\\ndata.metadata.language\\n\\nstring \\\\| null\\n\\n[\\u200b](https://docs.firecrawl.dev/v0/api-reference/endpoint/search#response-data-metadata-source-url)\\n\\ndata.metadata.sourceURL\\n\\nstring\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/v0/api-reference/endpoint/search.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/v0/api-reference/endpoint/search)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v0/search \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"query\": \"<string>\",\\n  \"pageOptions\": {\\n    \"onlyMainContent\": false,\\n    \"fetchPageContent\": true,\\n    \"includeHtml\": false,\\n    \"includeRawHtml\": false\\n  },\\n  \"searchOptions\": {\\n    \"limit\": 123\\n  }\\n}\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"data\": [\\\\\\n    {\\\\\\n      \"url\": \"<string>\",\\\\\\n      \"markdown\": \"<string>\",\\\\\\n      \"content\": \"<string>\",\\\\\\n      \"metadata\": {\\\\\\n        \"title\": \"<string>\",\\\\\\n        \"description\": \"<string>\",\\\\\\n        \"language\": \"<string>\",\\\\\\n        \"sourceURL\": \"<string>\"\\\\\\n      }\\\\\\n    }\\\\\\n  ]\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/api-reference/endpoint/extract-get',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nExtract Endpoints\\n\\nGet Extract Status\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nGET\\n\\n/\\n\\nextract\\n\\n/\\n\\n{id}\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request GET \\\\\\n  --url https://api.firecrawl.dev/v1/extract/{id} \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"data\": {},\\n  \"status\": \"completed\",\\n  \"expiresAt\": \"2023-11-07T05:31:56Z\"\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract-get#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Path Parameters\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract-get#parameter-id)\\n\\nid\\n\\nstring\\n\\nrequired\\n\\nThe ID of the extract job\\n\\n#### Response\\n\\n200 - application/json\\n\\nSuccessful response\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract-get#response-success)\\n\\nsuccess\\n\\nboolean\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract-get#response-data)\\n\\ndata\\n\\nobject\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract-get#response-status)\\n\\nstatus\\n\\nenum<string>\\n\\nThe current status of the extract job\\n\\nAvailable options:\\n\\n`completed`,\\n\\n`processing`,\\n\\n`failed`,\\n\\n`cancelled`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/extract-get#response-expires-at)\\n\\nexpiresAt\\n\\nstring\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/api-reference/endpoint/extract-get.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/extract-get)\\n\\n[Extract](https://docs.firecrawl.dev/api-reference/endpoint/extract) [Search](https://docs.firecrawl.dev/api-reference/endpoint/search)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request GET \\\\\\n  --url https://api.firecrawl.dev/v1/extract/{id} \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"data\": {},\\n  \"status\": \"completed\",\\n  \"expiresAt\": \"2023-11-07T05:31:56Z\"\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/api-reference/endpoint/llmstxt-get',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nLLMs.txt Status\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nGET\\n\\n/\\n\\nllmstxt\\n\\n/\\n\\n{id}\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request GET \\\\\\n  --url https://api.firecrawl.dev/v1/llmstxt/{id} \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\n404\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"status\": \"processing\",\\n  \"data\": {\\n    \"llmstxt\": \"<string>\",\\n    \"llmsfulltxt\": \"<string>\"\\n  },\\n  \"expiresAt\": \"2023-11-07T05:31:56Z\"\\n}\\n```\\n\\nGet the status and results of an LLMs.txt generation job. This endpoint allows you to check if the generation is complete and retrieve the generated content.\\n\\n### [\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/llmstxt-get\\\\#response-structure)  Response Structure\\n\\nThe response includes:\\n\\n- **success**: Boolean indicating if the request was successful\\n\\n- **status**: Current status of the generation job:\\n  - `processing`: Job is still running\\n  - `completed`: Job finished successfully\\n  - `failed`: Job encountered an error\\n- **data**: Generated content (when status is `completed`):\\n  - `llmstxt`: The generated LLMs.txt content\\n  - `llmsfulltxt`: Full text content (if showFullText was true)\\n- **expiresAt**: ISO timestamp indicating when the results will expire\\n\\n\\n### [\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/llmstxt-get\\\\#status-examples)  Status Examples\\n\\n1. **Processing Status**\\n\\n\\n\\n\\n\\nCopy\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n```json\\n{\\n     \"success\": true,\\n     \"status\": \"processing\",\\n     \"data\": {\\n       \"llmstxt\": \"# Firecrawl.dev llms.txt\\\\n\\\\n- [Web Data Extraction Tool](https://www.firecrawl.dev/)...\",\\n       \"llmsfulltxt\": \"# Firecrawl.dev llms-full.txt\\\\n\\\\n\"\\n     },\\n     \"expiresAt\": \"2025-03-03T23:19:18.000Z\"\\n}\\n\\n```\\n\\n2. **Completed Status**\\n\\n\\n\\n\\n\\nCopy\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n```json\\n{\\n     \"success\": true,\\n     \"status\": \"completed\",\\n     \"data\": {\\n       \"llmstxt\": \"# http://firecrawl.dev llms.txt\\\\n\\\\n- [Web Data Extraction Tool](https://www.firecrawl.dev/): Transform websites into clean, LLM-ready data effortlessly.\\\\n- [Flexible Web Scraping Pricing](https://www.firecrawl.dev/pricing): Flexible pricing plans for web scraping and data extraction.\",\\n       \"llmsfulltxt\": \"# http://firecrawl.dev llms-full.txt\\\\n\\\\n## Web Data Extraction Tool\\\\nIntroducing /extract - Get web data with a prompt...\"\\n     },\\n     \"expiresAt\": \"2025-03-03T22:45:50.000Z\"\\n}\\n\\n```\\n\\n\\n### [\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/llmstxt-get\\\\#error-handling)  Error Handling\\n\\nIf the generation job fails or cannot be found, youâ€™ll receive an appropriate error response:\\n\\nCopy\\n\\n```json\\n{\\n  \"success\": false,\\n  \"error\": \"LLMs.txt generation job not found\"\\n}\\n\\n```\\n\\n### [\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/llmstxt-get\\\\#polling-recommendations)  Polling Recommendations\\n\\n1. Poll every 2-3 seconds initially\\n2. Increase interval if still processing after 30 seconds\\n3. Stop polling if status is `completed` or `failed`\\n4. Implement exponential backoff to avoid rate limits\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/llmstxt-get#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Path Parameters\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/llmstxt-get#parameter-id)\\n\\nid\\n\\nstring\\n\\nrequired\\n\\nThe ID of the LLMs.txt generation job\\n\\n#### Response\\n\\n200\\n\\n200404\\n\\napplication/json\\n\\nSuccessful response\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/llmstxt-get#response-success)\\n\\nsuccess\\n\\nboolean\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/llmstxt-get#response-status)\\n\\nstatus\\n\\nenum<string>\\n\\nAvailable options:\\n\\n`processing`,\\n\\n`completed`,\\n\\n`failed`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/llmstxt-get#response-data)\\n\\ndata\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/llmstxt-get#response-data-llmstxt)\\n\\ndata.llmstxt\\n\\nstring\\n\\nThe generated LLMs.txt content\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/llmstxt-get#response-data-llmsfulltxt)\\n\\ndata.llmsfulltxt\\n\\nstring\\n\\nThe full text content when showFullText is true\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/llmstxt-get#response-expires-at)\\n\\nexpiresAt\\n\\nstring\\n\\nWhen the generated content will expire\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/api-reference/endpoint/llmstxt-get.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/llmstxt-get)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request GET \\\\\\n  --url https://api.firecrawl.dev/v1/llmstxt/{id} \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\n404\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"status\": \"processing\",\\n  \"data\": {\\n    \"llmstxt\": \"<string>\",\\n    \"llmsfulltxt\": \"<string>\"\\n  },\\n  \"expiresAt\": \"2023-11-07T05:31:56Z\"\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nScrape Endpoints\\n\\nBatch Scrape\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nPOST\\n\\n/\\n\\nbatch\\n\\n/\\n\\nscrape\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/batch/scrape \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"urls\": [\\\\\\n    \"<string>\"\\\\\\n  ],\\n  \"webhook\": {\\n    \"url\": \"<string>\",\\n    \"headers\": {},\\n    \"metadata\": {},\\n    \"events\": [\\\\\\n      \"completed\"\\\\\\n    ]\\n  },\\n  \"ignoreInvalidURLs\": false,\\n  \"formats\": [\\\\\\n    \"markdown\"\\\\\\n  ],\\n  \"onlyMainContent\": true,\\n  \"includeTags\": [\\\\\\n    \"<string>\"\\\\\\n  ],\\n  \"excludeTags\": [\\\\\\n    \"<string>\"\\\\\\n  ],\\n  \"headers\": {},\\n  \"waitFor\": 0,\\n  \"mobile\": false,\\n  \"skipTlsVerification\": false,\\n  \"timeout\": 30000,\\n  \"jsonOptions\": {\\n    \"schema\": {},\\n    \"systemPrompt\": \"<string>\",\\n    \"prompt\": \"<string>\"\\n  },\\n  \"actions\": [\\\\\\n    {\\\\\\n      \"type\": \"wait\",\\\\\\n      \"milliseconds\": 2,\\\\\\n      \"selector\": \"#my-element\"\\\\\\n    }\\\\\\n  ],\\n  \"location\": {\\n    \"country\": \"US\",\\n    \"languages\": [\\\\\\n      \"en-US\"\\\\\\n    ]\\n  },\\n  \"removeBase64Images\": true,\\n  \"blockAds\": true,\\n  \"proxy\": \"basic\"\\n}\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"id\": \"<string>\",\\n  \"url\": \"<string>\",\\n  \"invalidURLs\": [\\\\\\n    \"<string>\"\\\\\\n  ]\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Body\\n\\napplication/json\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-urls)\\n\\nurls\\n\\nstring\\\\[\\\\]\\n\\nrequired\\n\\nThe URL to scrape\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-webhook)\\n\\nwebhook\\n\\nobject\\n\\nA webhook specification object.\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-webhook-url)\\n\\nwebhook.url\\n\\nstring\\n\\nrequired\\n\\nThe URL to send the webhook to. This will trigger for batch scrape started (batch\\\\_scrape.started), every page scraped (batch\\\\_scrape.page) and when the batch scrape is completed (batch\\\\_scrape.completed or batch\\\\_scrape.failed). The response will be the same as the `/scrape` endpoint.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-webhook-headers)\\n\\nwebhook.headers\\n\\nobject\\n\\nHeaders to send to the webhook URL.\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-webhook-headers-key)\\n\\nwebhook.headers.{key}\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-webhook-metadata)\\n\\nwebhook.metadata\\n\\nobject\\n\\nCustom metadata that will be included in all webhook payloads for this crawl\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-webhook-events)\\n\\nwebhook.events\\n\\nenum<string>\\\\[\\\\]\\n\\nType of events that should be sent to the webhook URL. (default: all)\\n\\nAvailable options:\\n\\n`completed`,\\n\\n`page`,\\n\\n`failed`,\\n\\n`started`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-ignore-invalid-urls)\\n\\nignoreInvalidURLs\\n\\nboolean\\n\\ndefault:false\\n\\nIf invalid URLs are specified in the urls array, they will be ignored. Instead of them failing the entire request, a batch scrape using the remaining valid URLs will be created, and the invalid URLs will be returned in the invalidURLs field of the response.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-formats)\\n\\nformats\\n\\nenum<string>\\\\[\\\\]\\n\\nFormats to include in the output.\\n\\nAvailable options:\\n\\n`markdown`,\\n\\n`html`,\\n\\n`rawHtml`,\\n\\n`links`,\\n\\n`screenshot`,\\n\\n`screenshot@fullPage`,\\n\\n`json`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-only-main-content)\\n\\nonlyMainContent\\n\\nboolean\\n\\ndefault:true\\n\\nOnly return the main content of the page excluding headers, navs, footers, etc.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-include-tags)\\n\\nincludeTags\\n\\nstring\\\\[\\\\]\\n\\nTags to include in the output.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-exclude-tags)\\n\\nexcludeTags\\n\\nstring\\\\[\\\\]\\n\\nTags to exclude from the output.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-headers)\\n\\nheaders\\n\\nobject\\n\\nHeaders to send with the request. Can be used to send cookies, user-agent, etc.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-wait-for)\\n\\nwaitFor\\n\\ninteger\\n\\ndefault:0\\n\\nSpecify a delay in milliseconds before fetching the content, allowing the page sufficient time to load.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-mobile)\\n\\nmobile\\n\\nboolean\\n\\ndefault:false\\n\\nSet to true if you want to emulate scraping from a mobile device. Useful for testing responsive pages and taking mobile screenshots.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-skip-tls-verification)\\n\\nskipTlsVerification\\n\\nboolean\\n\\ndefault:false\\n\\nSkip TLS certificate verification when making requests\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-timeout)\\n\\ntimeout\\n\\ninteger\\n\\ndefault:30000\\n\\nTimeout in milliseconds for the request\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-json-options)\\n\\njsonOptions\\n\\nobject\\n\\nExtract object\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-json-options-schema)\\n\\njsonOptions.schema\\n\\nobject\\n\\nThe schema to use for the extraction (Optional)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-json-options-system-prompt)\\n\\njsonOptions.systemPrompt\\n\\nstring\\n\\nThe system prompt to use for the extraction (Optional)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-json-options-prompt)\\n\\njsonOptions.prompt\\n\\nstring\\n\\nThe prompt to use for the extraction without a schema (Optional)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-actions)\\n\\nactions\\n\\nobject\\\\[\\\\]\\n\\nActions to perform on the page before grabbing the content\\n\\n- Wait\\n- Screenshot\\n- Click\\n- Write text\\n- Press a key\\n- Scroll\\n- Scrape\\n- Execute JavaScript\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-actions-type)\\n\\nactions.type\\n\\nenum<string>\\n\\nrequired\\n\\nWait for a specified amount of milliseconds\\n\\nAvailable options:\\n\\n`wait`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-actions-milliseconds)\\n\\nactions.milliseconds\\n\\ninteger\\n\\nNumber of milliseconds to wait\\n\\nRequired range: `x >= 1`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-actions-selector)\\n\\nactions.selector\\n\\nstring\\n\\nQuery selector to find the element by\\n\\nExample:\\n\\n`\"#my-element\"`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-location)\\n\\nlocation\\n\\nobject\\n\\nLocation settings for the request. When specified, this will use an appropriate proxy if available and emulate the corresponding language and timezone settings. Defaults to \\'US\\' if not specified.\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-location-country)\\n\\nlocation.country\\n\\nstring\\n\\ndefault:US\\n\\nISO 3166-1 alpha-2 country code (e.g., \\'US\\', \\'AU\\', \\'DE\\', \\'JP\\')\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-location-languages)\\n\\nlocation.languages\\n\\nstring\\\\[\\\\]\\n\\nPreferred languages and locales for the request in order of priority. Defaults to the language of the specified location. See [https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Language](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Language)\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-remove-base64-images)\\n\\nremoveBase64Images\\n\\nboolean\\n\\nRemoves all base 64 images from the output, which may be overwhelmingly long. The image\\'s alt text remains in the output, but the URL is replaced with a placeholder.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-block-ads)\\n\\nblockAds\\n\\nboolean\\n\\ndefault:true\\n\\nEnables ad-blocking and cookie popup blocking.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#body-proxy)\\n\\nproxy\\n\\nenum<string>\\n\\nSpecifies the type of proxy to use.\\n\\n- **basic**: Proxies for scraping sites with none to basic anti-bot solutions. Fast and usually works.\\n- **stealth**: Stealth proxies for scraping sites with advanced anti-bot solutions. Slower, but more reliable on certain sites.\\n\\nIf you do not specify a proxy, Firecrawl will automatically attempt to determine which one you need based on the target site.\\n\\nAvailable options:\\n\\n`basic`,\\n\\n`stealth`\\n\\n#### Response\\n\\n200\\n\\n200402429500\\n\\napplication/json\\n\\nSuccessful response\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#response-success)\\n\\nsuccess\\n\\nboolean\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#response-id)\\n\\nid\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#response-url)\\n\\nurl\\n\\nstring\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#response-invalid-urls)\\n\\ninvalidURLs\\n\\nstring\\\\[\\\\] \\\\| null\\n\\nIf ignoreInvalidURLs is true, this is an array containing the invalid URLs that were specified in the request. If there were no invalid URLs, this will be an empty array. If ignoreInvalidURLs is false, this field will be undefined.\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/api-reference/endpoint/batch-scrape.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/batch-scrape)\\n\\n[Scrape](https://docs.firecrawl.dev/api-reference/endpoint/scrape) [Get Batch Scrape Status](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/batch/scrape \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"urls\": [\\\\\\n    \"<string>\"\\\\\\n  ],\\n  \"webhook\": {\\n    \"url\": \"<string>\",\\n    \"headers\": {},\\n    \"metadata\": {},\\n    \"events\": [\\\\\\n      \"completed\"\\\\\\n    ]\\n  },\\n  \"ignoreInvalidURLs\": false,\\n  \"formats\": [\\\\\\n    \"markdown\"\\\\\\n  ],\\n  \"onlyMainContent\": true,\\n  \"includeTags\": [\\\\\\n    \"<string>\"\\\\\\n  ],\\n  \"excludeTags\": [\\\\\\n    \"<string>\"\\\\\\n  ],\\n  \"headers\": {},\\n  \"waitFor\": 0,\\n  \"mobile\": false,\\n  \"skipTlsVerification\": false,\\n  \"timeout\": 30000,\\n  \"jsonOptions\": {\\n    \"schema\": {},\\n    \"systemPrompt\": \"<string>\",\\n    \"prompt\": \"<string>\"\\n  },\\n  \"actions\": [\\\\\\n    {\\\\\\n      \"type\": \"wait\",\\\\\\n      \"milliseconds\": 2,\\\\\\n      \"selector\": \"#my-element\"\\\\\\n    }\\\\\\n  ],\\n  \"location\": {\\n    \"country\": \"US\",\\n    \"languages\": [\\\\\\n      \"en-US\"\\\\\\n    ]\\n  },\\n  \"removeBase64Images\": true,\\n  \"blockAds\": true,\\n  \"proxy\": \"basic\"\\n}\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"id\": \"<string>\",\\n  \"url\": \"<string>\",\\n  \"invalidURLs\": [\\\\\\n    \"<string>\"\\\\\\n  ]\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/api-reference/endpoint/map',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nMap Endpoints\\n\\nMap\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nPOST\\n\\n/\\n\\nmap\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/map \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"url\": \"<string>\",\\n  \"search\": \"<string>\",\\n  \"ignoreSitemap\": true,\\n  \"sitemapOnly\": false,\\n  \"includeSubdomains\": false,\\n  \"limit\": 5000,\\n  \"timeout\": 123\\n}\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"links\": [\\\\\\n    \"<string>\"\\\\\\n  ]\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/map#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Body\\n\\napplication/json\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/map#body-url)\\n\\nurl\\n\\nstring\\n\\nrequired\\n\\nThe base URL to start crawling from\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/map#body-search)\\n\\nsearch\\n\\nstring\\n\\nSearch query to use for mapping. During the Alpha phase, the \\'smart\\' part of the search functionality is limited to 1000 search results. However, if map finds more results, there is no limit applied.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/map#body-ignore-sitemap)\\n\\nignoreSitemap\\n\\nboolean\\n\\ndefault:true\\n\\nIgnore the website sitemap when crawling.\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/map#body-sitemap-only)\\n\\nsitemapOnly\\n\\nboolean\\n\\ndefault:false\\n\\nOnly return links found in the website sitemap\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/map#body-include-subdomains)\\n\\nincludeSubdomains\\n\\nboolean\\n\\ndefault:false\\n\\nInclude subdomains of the website\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/map#body-limit)\\n\\nlimit\\n\\ninteger\\n\\ndefault:5000\\n\\nMaximum number of links to return\\n\\nRequired range: `x <= 5000`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/map#body-timeout)\\n\\ntimeout\\n\\ninteger\\n\\nTimeout in milliseconds. There is no timeout by default.\\n\\n#### Response\\n\\n200\\n\\n200402429500\\n\\napplication/json\\n\\nSuccessful response\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/map#response-success)\\n\\nsuccess\\n\\nboolean\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/map#response-links)\\n\\nlinks\\n\\nstring\\\\[\\\\]\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/api-reference/endpoint/map.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/map)\\n\\n[Get Crawl Errors](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get-errors) [Extract](https://docs.firecrawl.dev/api-reference/endpoint/extract)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.firecrawl.dev/v1/map \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"url\": \"<string>\",\\n  \"search\": \"<string>\",\\n  \"ignoreSitemap\": true,\\n  \"sitemapOnly\": false,\\n  \"includeSubdomains\": false,\\n  \"limit\": 5000,\\n  \"timeout\": 123\\n}\\'\\n```\\n\\n200\\n\\n402\\n\\n429\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"links\": [\\\\\\n    \"<string>\"\\\\\\n  ]\\n}\\n```'},\n",
              " {'url': 'https://docs.firecrawl.dev/api-reference/endpoint/credit-usage',\n",
              "  'markdown': '[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/light.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/dark.svg)](https://firecrawl.dev/)\\n\\nv1\\n\\nSearch or ask...\\n\\nCtrl K\\n\\nSearch...\\n\\nNavigation\\n\\nAccount Endpoints\\n\\nCredit Usage\\n\\n[Documentation](https://docs.firecrawl.dev/introduction) [SDKs](https://docs.firecrawl.dev/sdks/overview) [Learn](https://www.firecrawl.dev/blog/category/tutorials) [API Reference](https://docs.firecrawl.dev/api-reference/introduction)\\n\\nGET\\n\\n/\\n\\nteam\\n\\n/\\n\\ncredit-usage\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request GET \\\\\\n  --url https://api.firecrawl.dev/v1/team/credit-usage \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\n404\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"data\": {\\n    \"remaining_credits\": 1000\\n  }\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/credit-usage#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Response\\n\\n200\\n\\n200404500\\n\\napplication/json\\n\\nSuccessful response\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/credit-usage#response-success)\\n\\nsuccess\\n\\nboolean\\n\\nExample:\\n\\n`true`\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/credit-usage#response-data)\\n\\ndata\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.firecrawl.dev/api-reference/endpoint/credit-usage#response-data-remaining-credits)\\n\\ndata.remaining\\\\_credits\\n\\nnumber\\n\\nNumber of credits remaining for the team\\n\\nExample:\\n\\n`1000`\\n\\n[Suggest edits](https://github.com/hellofirecrawl/docs/edit/main/api-reference/endpoint/credit-usage.mdx) [Raise issue](https://github.com/hellofirecrawl/docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/credit-usage)\\n\\n[Search](https://docs.firecrawl.dev/api-reference/endpoint/search)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request GET \\\\\\n  --url https://api.firecrawl.dev/v1/team/credit-usage \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\n404\\n\\n500\\n\\nCopy\\n\\n```\\n{\\n  \"success\": true,\\n  \"data\": {\\n    \"remaining_credits\": 1000\\n  }\\n}\\n```'}]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_markdown_from_urls(urls: list[str]):\n",
        "    batch_scrape_result = fire.batch_scrape_urls(urls, {'formats': ['markdown']})\n",
        "\n",
        "    all_markdown = []\n",
        "    for page in batch_scrape_result['data']:\n",
        "        all_markdown.append({\n",
        "            \"url\": page['metadata']['url'],\n",
        "            'markdown': page['markdown']\n",
        "        })\n",
        "\n",
        "    return all_markdown\n",
        "\n",
        "all_markdowns = get_markdown_from_urls(api_doc_urls)\n",
        "all_markdowns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqGqgDJGlQ8E",
        "outputId": "f7623a62-fd1d-4246-d459-931d8417300f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```curl\n",
            "curl --request POST \\\n",
            "  --url https://api.firecrawl.dev/v1/scrape \\\n",
            "  --header 'Authorization: Bearer <token>' \\\n",
            "  --header 'Content-Type: application/json' \\\n",
            "  --data '{\n",
            "  \"url\": \"ai-jason.com\",\n",
            "  \"formats\": [\n",
            "    \"markdown\"\n",
            "  ],\n",
            "  \"onlyMainContent\": true,\n",
            "  \"includeTags\": [],\n",
            "  \"excludeTags\": [],\n",
            "  \"headers\": {},\n",
            "  \"waitFor\": 0,\n",
            "  \"mobile\": false,\n",
            "  \"skipTlsVerification\": false,\n",
            "  \"timeout\": 30000,\n",
            "  \"jsonOptions\": {\n",
            "    \"schema\": {},\n",
            "    \"systemPrompt\": \"<string>\",\n",
            "    \"prompt\": \"<string>\"\n",
            "  },\n",
            "  \"actions\": [],\n",
            "  \"location\": {\n",
            "    \"country\": \"US\",\n",
            "    \"languages\": [\n",
            "      \"en-US\"\n",
            "    ]\n",
            "  },\n",
            "  \"removeBase64Images\": true,\n",
            "  \"blockAds\": true,\n",
            "  \"proxy\": \"basic\"\n",
            "}'\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "def cag_response_call(prompt):\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        contents=[json.dumps(all_markdowns),\n",
        "                  prompt])\n",
        "    return(response.text)\n",
        "\n",
        "cag_response = cag_response_call(\"Help me generate api request in curl for scrape'ai-jason.com' using firecrawl rest api, return only the curl command\")\n",
        "print(cag_response)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}